{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>articleID</th>\n",
       "      <th>truerating</th>\n",
       "      <th>bin_truerating</th>\n",
       "      <th>round_truerating</th>\n",
       "      <th>sentence_num</th>\n",
       "      <th>headline_word</th>\n",
       "      <th>recog_score</th>\n",
       "      <th>recog_zscore</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>recall_zscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>another</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.885513</td>\n",
       "      <td>-0.689255</td>\n",
       "      <td>0.491141</td>\n",
       "      <td>0.519220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>another</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.885513</td>\n",
       "      <td>-0.689255</td>\n",
       "      <td>0.491141</td>\n",
       "      <td>0.519220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>another</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>0.885513</td>\n",
       "      <td>-0.689255</td>\n",
       "      <td>0.491141</td>\n",
       "      <td>0.519220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>another</td>\n",
       "      <td>15</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.885513</td>\n",
       "      <td>-0.689255</td>\n",
       "      <td>0.491141</td>\n",
       "      <td>0.519220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>another</td>\n",
       "      <td>18</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>14</td>\n",
       "      <td>False</td>\n",
       "      <td>0.885513</td>\n",
       "      <td>-0.689255</td>\n",
       "      <td>0.491141</td>\n",
       "      <td>0.519220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72609</th>\n",
       "      <td>fre_quent</td>\n",
       "      <td>129</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>0.912135</td>\n",
       "      <td>0.550954</td>\n",
       "      <td>0.503321</td>\n",
       "      <td>0.899193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72610</th>\n",
       "      <td>palm_oil</td>\n",
       "      <td>129</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>0.914344</td>\n",
       "      <td>0.653833</td>\n",
       "      <td>0.467906</td>\n",
       "      <td>-0.205611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72611</th>\n",
       "      <td>advice</td>\n",
       "      <td>129</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>0.883824</td>\n",
       "      <td>-0.767944</td>\n",
       "      <td>0.469666</td>\n",
       "      <td>-0.150698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72612</th>\n",
       "      <td>strive</td>\n",
       "      <td>129</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>0.905740</td>\n",
       "      <td>0.253022</td>\n",
       "      <td>0.453770</td>\n",
       "      <td>-0.646597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72613</th>\n",
       "      <td>minimizing</td>\n",
       "      <td>129</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>0.907326</td>\n",
       "      <td>0.326910</td>\n",
       "      <td>0.454079</td>\n",
       "      <td>-0.636974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72614 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  articleID  truerating  bin_truerating  round_truerating  \\\n",
       "0         another          1        -2.0           False              -2.0   \n",
       "1         another          1        -2.0           False              -2.0   \n",
       "2         another          2        -2.0           False              -2.0   \n",
       "3         another         15        -2.0           False              -2.0   \n",
       "4         another         18        -2.0           False              -2.0   \n",
       "...           ...        ...         ...             ...               ...   \n",
       "72609   fre_quent        129        -1.8           False              -2.0   \n",
       "72610    palm_oil        129        -1.8           False              -2.0   \n",
       "72611      advice        129        -1.8           False              -2.0   \n",
       "72612      strive        129        -1.8           False              -2.0   \n",
       "72613  minimizing        129        -1.8           False              -2.0   \n",
       "\n",
       "      sentence_num  headline_word  recog_score  recog_zscore  recall_score  \\\n",
       "0                0           True     0.885513     -0.689255      0.491141   \n",
       "1                3          False     0.885513     -0.689255      0.491141   \n",
       "2               12          False     0.885513     -0.689255      0.491141   \n",
       "3                0           True     0.885513     -0.689255      0.491141   \n",
       "4               14          False     0.885513     -0.689255      0.491141   \n",
       "...            ...            ...          ...           ...           ...   \n",
       "72609           13          False     0.912135      0.550954      0.503321   \n",
       "72610           15          False     0.914344      0.653833      0.467906   \n",
       "72611           20          False     0.883824     -0.767944      0.469666   \n",
       "72612           20          False     0.905740      0.253022      0.453770   \n",
       "72613           20          False     0.907326      0.326910      0.454079   \n",
       "\n",
       "       recall_zscore  \n",
       "0           0.519220  \n",
       "1           0.519220  \n",
       "2           0.519220  \n",
       "3           0.519220  \n",
       "4           0.519220  \n",
       "...              ...  \n",
       "72609       0.899193  \n",
       "72610      -0.205611  \n",
       "72611      -0.150698  \n",
       "72612      -0.646597  \n",
       "72613      -0.636974  \n",
       "\n",
       "[72614 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('ClimateFeedback_articles_202101.xlsx')\n",
    "\n",
    "# tokenize sentences to keep track of sentence numbers\n",
    "df['tokenized_sentences'] = df.apply(lambda row: nltk.sent_tokenize(row['text']), axis=1)\n",
    "df['tokenized_sentences'] = df.apply(lambda row: [row['title, original source']] + row['tokenized_sentences'], axis=1)\n",
    "df['sentence_num'] = df.apply(lambda row: [i for i in range(0, len(row['tokenized_sentences']))], axis=1)\n",
    "\n",
    "# split sentences into rows\n",
    "df = df.explode(['tokenized_sentences', 'sentence_num'])\n",
    "\n",
    "# clean up sentences (lower case, punctuation)\n",
    "df['tokenized_sentences'] = df.apply(lambda row: row['tokenized_sentences'].lower(), axis=1)\n",
    "df['tokenized_sentences'] = df.apply(lambda row: row['tokenized_sentences'].translate(str.maketrans('', '', string.digits)), axis=1)\n",
    "df['tokenized_sentences'] = df.apply(lambda row: row['tokenized_sentences'].translate(str.maketrans('-', '_')), axis=1)\n",
    "df['tokenized_sentences'] = df.apply(lambda row: row['tokenized_sentences'].translate(str.maketrans('–', '_')), axis=1)\n",
    "df['tokenized_sentences'] = df.apply(lambda row: row['tokenized_sentences'].translate(str.maketrans('—', '_')), axis=1)\n",
    "remove = string.punctuation\n",
    "remove = remove.replace('_', \"\")\n",
    "df['tokenized_sentences'] = df.apply(lambda row: row['tokenized_sentences'].translate(str.maketrans('', '', remove)), axis=1)\n",
    "df['tokenized_sentences'] = df.apply(lambda row: row['tokenized_sentences'].translate(str.maketrans('', '', '“”‘’')), axis=1)\n",
    "\n",
    "# tokenize each sentence row\n",
    "df['tokenized_words'] = df.apply(lambda row: nltk.word_tokenize(row['tokenized_sentences']), axis=1)\n",
    "\n",
    "# remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['tokenized_words'] = df.apply(lambda row: [w for w in row['tokenized_words'] if not w in stop_words], axis=1)\n",
    "\n",
    "# split words into rows\n",
    "df = df.explode('tokenized_words')\n",
    "\n",
    "# new vars\n",
    "df['bin_truerating'] = df['truerating'] > 0\n",
    "df['round_truerating'] = round(df['truerating'])\n",
    "df['headline_word'] = df['sentence_num'] == 0\n",
    "\n",
    "# merge in memorability scores\n",
    "df_predictions = pd.read_csv('CC_allwords_scores.csv')\n",
    "df = df.merge(df_predictions, how='inner', left_on='tokenized_words', right_on='word')\n",
    "\n",
    "# add zscores for memorability scores\n",
    "df['recog_zscore'] = stats.zscore(df['recognition_predictions'])\n",
    "df['recall_zscore'] = stats.zscore(df['recall_predictions'])\n",
    "\n",
    "# clean up columns\n",
    "df = df.rename(columns={'UniqNO':'articleID', 'recognition_predictions':'recog_score', 'recall_predictions':'recall_score'})\n",
    "outdf = df[['word', 'articleID', 'truerating', 'bin_truerating', 'round_truerating', 'sentence_num', 'headline_word', 'recog_score', 'recog_zscore', 'recall_score', 'recall_zscore']]\n",
    "\n",
    "\n",
    "outdf.reset_index()\n",
    "\n",
    "outdf.to_csv('CCarticles_allwords_memorability_dataset.csv')\n",
    "\n",
    "outdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
