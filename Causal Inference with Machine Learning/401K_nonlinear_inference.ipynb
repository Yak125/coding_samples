{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "440900dd",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48531654",
   "metadata": {},
   "source": [
    "### Part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ae78d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LassoCV, RidgeCV, ElasticNetCV, LinearRegression, Ridge, Lasso, LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "import patsy\n",
    "import warnings\n",
    "from sklearn.base import BaseEstimator, clone\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from IPython.display import Markdown\n",
    "import os\n",
    "import seaborn as sns\n",
    "from flaml import AutoML\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f27fb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from formulaic import Formula\n",
    "\n",
    "class FormulaTransformer(TransformerMixin, BaseEstimator):\n",
    "\n",
    "    def __init__(self, formula, array=False):\n",
    "        self.formula = formula\n",
    "        self.array = array\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        df = Formula(self.formula).get_model_matrix(X)\n",
    "        if self.array:\n",
    "            return df.values\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9439ec0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dml(X, D, y, modely, modeld, *, nfolds, classifier=False):\n",
    "    '''\n",
    "    DML for the Partially Linear Model setting with cross-fitting\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    X: the controls\n",
    "    D: the treatment\n",
    "    y: the outcome\n",
    "    modely: the ML model for predicting the outcome y\n",
    "    modeld: the ML model for predicting the treatment D\n",
    "    nfolds: the number of folds in cross-fitting\n",
    "    classifier: bool, whether the modeld is a classifier or a regressor\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    point: the point estimate of the treatment effect of D on y\n",
    "    stderr: the standard error of the treatment effect\n",
    "    yhat: the cross-fitted predictions for the outcome y\n",
    "    Dhat: the cross-fitted predictions for the treatment D\n",
    "    resy: the outcome residuals\n",
    "    resD: the treatment residuals\n",
    "    epsilon: the final residual-on-residual OLS regression residual\n",
    "    '''\n",
    "    cv = KFold(n_splits=nfolds, shuffle=True, random_state=123) # shuffled k-folds\n",
    "    yhat = cross_val_predict(modely, X, y, cv=cv, n_jobs=-1) # out-of-fold predictions for y\n",
    "    # out-of-fold predictions for D\n",
    "    # use predict or predict_proba dependent on classifier or regressor for D\n",
    "    if classifier:\n",
    "        Dhat = cross_val_predict(modeld, X, D, cv=cv, method='predict_proba', n_jobs=-1)[:, 1]\n",
    "    else:\n",
    "        Dhat = cross_val_predict(modeld, X, D, cv=cv, n_jobs=-1)\n",
    "    # calculate outcome and treatment residuals\n",
    "    resy = y - yhat\n",
    "    resD = D - Dhat\n",
    "\n",
    "    # final stage ols based point estimate and standard error\n",
    "    point = np.mean(resy * resD) / np.mean(resD**2)\n",
    "    epsilon = resy - point * resD\n",
    "    var = np.mean(epsilon**2 * resD**2) / np.mean(resD**2)**2\n",
    "    stderr = np.sqrt(var / X.shape[0])\n",
    "\n",
    "    return point, stderr, yhat, Dhat, resy, resD, epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "174b4a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dml_dirty(X, D, y, modely_list, modeld_list, *,\n",
    "              stacker=LinearRegression(), nfolds, classifier=False):\n",
    "    '''\n",
    "    DML for the Partially Linear Model setting with semi-cross-fitting\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    X: the controls\n",
    "    D: the treatment\n",
    "    y: the outcome\n",
    "    modely: the ML model for predicting the outcome y\n",
    "    modeld: the ML model for predicting the treatment D\n",
    "    stacker: model used to aggregate predictions of each of the base models\n",
    "    nfolds: the number of folds in cross-fitting\n",
    "    classifier: bool, whether the modeld is a classifier or a regressor\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    point: the point estimate of the treatment effect of D on y\n",
    "    stderr: the standard error of the treatment effect\n",
    "    yhat: the cross-fitted predictions for the outcome y\n",
    "    Dhat: the cross-fitted predictions for the treatment D\n",
    "    resy: the outcome residuals\n",
    "    resD: the treatment residuals\n",
    "    epsilon: the final residual-on-residual OLS regression residual\n",
    "    '''\n",
    "    # construct out-of-fold predictions for each model\n",
    "    cv = KFold(n_splits=nfolds, shuffle=True, random_state=123)\n",
    "    yhats = np.array([cross_val_predict(modely, X, y, cv=cv, n_jobs=-1) for modely in modely_list]).T\n",
    "    if classifier:\n",
    "        Dhats = np.array([cross_val_predict(modeld, X, D, cv=cv, method='predict_proba', n_jobs=-1)[:, 1]\n",
    "                         for modeld in modeld_list]).T\n",
    "    else:\n",
    "        Dhats = np.array([cross_val_predict(modeld, X, D, cv=cv, n_jobs=-1) for modeld in modeld_list]).T\n",
    "    # calculate stacked residuals by finding optimal coefficients\n",
    "    # and weigthing out-of-sample predictions by these coefficients\n",
    "    yhat = stacker.fit(yhats, y).predict(yhats)\n",
    "    Dhat = stacker.fit(Dhats, D).predict(Dhats)\n",
    "    resy = y - yhat\n",
    "    resD = D - Dhat\n",
    "    # go with the stacked residuals\n",
    "    point = np.mean(resy * resD) / np.mean(resD**2)\n",
    "    epsilon = resy - point * resD\n",
    "    var = np.mean(epsilon**2 * resD**2) / np.mean(resD**2)**2\n",
    "    stderr = np.sqrt(var / X.shape[0])\n",
    "    return point, stderr, yhat, Dhat, resy, resD, epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68867f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dr(X, D, y, modely0, modely1, modeld, *, trimming=0.01, nfolds):\n",
    "    '''\n",
    "    DML for the Interactive Regression Model setting (Doubly Robust Learning)\n",
    "    with cross-fitting\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    X: the controls\n",
    "    D: the treatment\n",
    "    y: the outcome\n",
    "    modely0: the ML model for predicting the outcome y in the control population\n",
    "    modely1: the ML model for predicting the outcome y in the treated population\n",
    "    modeld: the ML model for predicting the treatment D\n",
    "    trimming: threshold below which to trim propensities\n",
    "    nfolds: the number of folds in cross-fitting\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    point: the point estimate of the treatment effect of D on y\n",
    "    stderr: the standard error of the treatment effect\n",
    "    yhat: the cross-fitted predictions for the outcome y\n",
    "    Dhat: the cross-fitted predictions for the outcome D\n",
    "    resy: the outcome residuals\n",
    "    resD: the treatment residuals\n",
    "    drhat: the doubly robust quantity for each sample\n",
    "    '''\n",
    "    cv = KFold(n_splits=nfolds, shuffle=True, random_state=123)\n",
    "    yhat0, yhat1 = np.zeros(y.shape), np.zeros(y.shape)\n",
    "    # we will fit a model E[Y| D, X] by fitting a separate model for D==0\n",
    "    # and a separate model for D==1.\n",
    "    for train, test in cv.split(X, y):\n",
    "        # train a model on training data that received treatment zero and predict on all data in test set\n",
    "        yhat0[test] = clone(modely0).fit(X.iloc[train][D[train]==0], y[train][D[train]==0]).predict(X.iloc[test])\n",
    "        # train a model on training data that received treatment one and predict on all data in test set\n",
    "        yhat1[test] = clone(modely1).fit(X.iloc[train][D[train]==1], y[train][D[train]==1]).predict(X.iloc[test])\n",
    "    # prediction for observed treatment\n",
    "    yhat = yhat0 * (1 - D) + yhat1 * D\n",
    "    # propensity scores\n",
    "    Dhat = cross_val_predict(modeld, X, D, cv=cv, method='predict_proba', n_jobs=-1)[:, 1]\n",
    "    Dhat = np.clip(Dhat, trimming, 1 - trimming)\n",
    "    # doubly robust quantity for every sample\n",
    "    drhat = yhat1 - yhat0 + (y - yhat) * (D/Dhat - (1 - D)/(1 - Dhat))\n",
    "    point = np.mean(drhat)\n",
    "    var = np.var(drhat)\n",
    "    stderr = np.sqrt(var / X.shape[0])\n",
    "    return point, stderr, yhat, Dhat, y - yhat, D - Dhat, drhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5266cd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dr_dirty(X, D, y, modely0_list, modely1_list, modeld_list, *,\n",
    "             stacker=LinearRegression(), trimming=0.01, nfolds):\n",
    "    '''\n",
    "    DML for the Interactive Regression Model setting (Doubly Robust Learning)\n",
    "    with cross-fitting\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    X: the controls\n",
    "    D: the treatment\n",
    "    y: the outcome\n",
    "    modely_list: list of ML models for predicting the outcome y\n",
    "    modeld_list: list of ML models for predicting the treatment D\n",
    "    stacker: model used to aggregate predictions of each of the base models\n",
    "    trimming: threshold below which to trim propensities\n",
    "    nfolds: the number of folds in cross-fitting\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    point: the point estimate of the treatment effect of D on y\n",
    "    stderr: the standard error of the treatment effect\n",
    "    yhat: the cross-fitted predictions for the outcome y\n",
    "    Dhat: the cross-fitted predictions for the outcome D\n",
    "    resy: the outcome residuals\n",
    "    resD: the treatment residuals\n",
    "    drhat: the doubly robust quantity for each sample\n",
    "    '''\n",
    "    cv = KFold(n_splits=nfolds, shuffle=True, random_state=123)\n",
    "\n",
    "    # we will fit a model E[Y| D, X] by fitting a separate model for D==0\n",
    "    # and a separate model for D==1. We do that for each model type in modely_list\n",
    "    yhats0, yhats1 = np.zeros((y.shape[0], len(modely0_list))), np.zeros((y.shape[0], len(modely1_list)))\n",
    "    for train, test in cv.split(X, y):\n",
    "        for it, modely0 in enumerate(modely0_list):\n",
    "            yhats0[test, it] = clone(modely0).fit(X.iloc[train][D[train]==0], y[train][D[train]==0]).predict(X.iloc[test])\n",
    "        for it, modely1 in enumerate(modely1_list):\n",
    "            yhats1[test, it] = clone(modely1).fit(X.iloc[train][D[train]==1], y[train][D[train]==1]).predict(X.iloc[test])\n",
    "\n",
    "    # calculate stacking weights for the outcome model for each population\n",
    "    # and combine the outcome model predictions\n",
    "    yhat0 = clone(stacker).fit(yhats0[D==0], y[D==0]).predict(yhats0)\n",
    "    yhat1 = clone(stacker).fit(yhats1[D==1], y[D==1]).predict(yhats1)\n",
    "\n",
    "    # prediction for observed treatment using the stacked model\n",
    "    yhat = yhat0 * (1 - D) + yhat1 * D\n",
    "\n",
    "    # propensity scores\n",
    "    Dhats = np.array([cross_val_predict(modeld, X, D, cv=cv, method='predict_proba', n_jobs=-1)[:, 1]\n",
    "                     for modeld in modeld_list]).T\n",
    "    # construct coefficients on each model based on stacker\n",
    "    Dhat = clone(stacker).fit(Dhats, D).predict(Dhats)\n",
    "    # trim propensities\n",
    "    Dhat = np.clip(Dhat, trimming, 1 - trimming)\n",
    "\n",
    "    # doubly robust quantity for every sample\n",
    "    drhat = yhat1 - yhat0 + (y - yhat) * (D/Dhat - (1 - D)/(1 - Dhat))\n",
    "    point = np.mean(drhat)\n",
    "    var = np.var(drhat)\n",
    "    stderr = np.sqrt(var / X.shape[0])\n",
    "    return point, stderr, yhat, Dhat, y - yhat, D - Dhat, drhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3f73723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(point, stderr, yhat, Dhat, resy, resD, epsilon, X, D, y, *, name):\n",
    "    '''\n",
    "    Convenience summary function that takes the results of the DML function\n",
    "    and summarizes several estimation quantities and performance metrics.\n",
    "    '''\n",
    "    return pd.DataFrame({'estimate': point, # point estimate\n",
    "                         'stderr': stderr, # standard error\n",
    "                         'lower': point - 1.96*stderr, # lower end of 95% confidence interval\n",
    "                         'upper': point + 1.96*stderr, # upper end of 95% confidence interval\n",
    "                         'rmse y': np.sqrt(np.mean(resy**2)), # RMSE of model that predicts outcome y\n",
    "                         'rmse D': np.sqrt(np.mean(resD**2)), # RMSE of model that predicts treatment D\n",
    "                         'accuracy D': np.mean(np.abs(resD) < .5), # binary classification accuracy of model for D\n",
    "                         }, index=[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2e05302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_PLM_table(X, D, y):\n",
    "    table = pd.DataFrame()\n",
    "    \n",
    "    # Double Lasso with crossfitting\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "    lassoy = make_pipeline(transformer, StandardScaler(), LassoCV(cv=cv))\n",
    "    lassod = make_pipeline(transformer, StandardScaler(), LassoCV(cv=cv))\n",
    "    result = dml(X, D, y, lassoy, lassod, nfolds=3)\n",
    "    result = summary(*result, X, D, y, name='double lasso')\n",
    "    pd.concat([table, result])\n",
    "    \n",
    "    \n",
    "    # Penalized Logistic Regression for D\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "    lassoy = make_pipeline(transformer, StandardScaler(), LassoCV(cv=cv))\n",
    "    lgrd = make_pipeline(transformer, StandardScaler(), LogisticRegressionCV(cv=cv))\n",
    "    result = dml(X, D, y, lassoy, lgrd, nfolds=3, classifier=True)\n",
    "    table = pd.concat([table, summary(*result,  X, D, y, name='lasso/logistic')])\n",
    "    \n",
    "    # Random Forest\n",
    "    rfy = make_pipeline(transformer, RandomForestRegressor(n_estimators=100, min_samples_leaf=10, ccp_alpha=.001))\n",
    "    rfd = make_pipeline(transformer, RandomForestClassifier(n_estimators=100, min_samples_leaf=10, ccp_alpha=.001))\n",
    "    result = dml(X, D, y, rfy, rfd, nfolds=3, classifier=True)\n",
    "    table = pd.concat([table, summary(*result,  X, D, y, name='random forest')])\n",
    "\n",
    "    # Decision Trees\n",
    "    dtry = make_pipeline(transformer, DecisionTreeRegressor(min_samples_leaf=10, ccp_alpha=.001))\n",
    "    dtrd = make_pipeline(transformer, DecisionTreeClassifier(min_samples_leaf=10, ccp_alpha=.001))\n",
    "    result = dml(X, D, y, dtry, dtrd, nfolds=3, classifier=True)\n",
    "    table = pd.concat([table, summary(*result,  X, D, y, name='decision tree')])\n",
    "\n",
    "    # Boosted Trees\n",
    "    gbfy = make_pipeline(transformer, GradientBoostingRegressor(max_depth=2, n_iter_no_change=5))\n",
    "    gbfd = make_pipeline(transformer, GradientBoostingClassifier(max_depth=2, n_iter_no_change=5))\n",
    "    result = dml(X, D, y, gbfy, gbfd, nfolds=3, classifier=True)\n",
    "    table = pd.concat([table, summary(*result,  X, D, y, name='boosted forest')])\n",
    "\n",
    "    # AutoML\n",
    "    flamly = make_pipeline(transformer, AutoML(time_budget=100, task='regression', early_stop=True,\n",
    "                                        eval_method='cv', n_splits=3, metric='r2', verbose=3))\n",
    "    flamld = make_pipeline(transformer, AutoML(time_budget=100, task='classification', early_stop=True,\n",
    "                                               eval_method='cv', n_splits=3, metric='r2', verbose=3))\n",
    "    result = dml(X, D, y, flamly, flamld, nfolds=3, classifier=True)\n",
    "    table = pd.concat([table, summary(*result,  X, D, y, name='automl')])\n",
    "\n",
    "    # AutoML semi-crossfit\n",
    "#     flamly = make_pipeline(transformer, AutoML(time_budget=100, task='regression', early_stop=True,\n",
    "#                                     eval_method='cv', n_splits=3, metric='r2', verbose=0))\n",
    "#     flamld = make_pipeline(transformer, AutoML(time_budget=100, task='classification', early_stop=True,\n",
    "#                                            eval_method='cv', n_splits=3, metric='r2', verbose=0))\n",
    "#     flamly.fit(X, y)\n",
    "#     besty = make_pipeline(transformer, clone(flamly[-1].best_model_for_estimator(flamly[-1].best_estimator)))\n",
    "#     flamld.fit(X, D)\n",
    "#     bestd = make_pipeline(transformer, clone(flamld[-1].best_model_for_estimator(flamld[-1].best_estimator)))\n",
    "#     result = dml(X, D, y, besty, bestd, nfolds=3, classifier=True)\n",
    "#     table = pd.concat([table, summary(*result,  X, D, y, name='automl (semi-cfit)')])\n",
    "\n",
    "    # Stacked semi-crossfit\n",
    "    result = dml_dirty(X, D, y, [lassoy, rfy, dtry, gbfy], [lgrd, rfd, dtrd, gbfd],\n",
    "                   nfolds=3, classifier=True)\n",
    "    table = pd.concat([table, summary(*result,  X, D, y, name='stacked (semi-cfit)')])\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9869df13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_IRM_table(X, D, y):\n",
    "    table = pd.DataFrame()\n",
    "    \n",
    "    # Lasso/Logistic\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "    lassoy = make_pipeline(transformer, StandardScaler(), LassoCV(cv=cv))\n",
    "    lgrd = make_pipeline(transformer, StandardScaler(), LogisticRegressionCV(cv=cv))\n",
    "    result = dr(X, D, y, lassoy, lassoy, lgrd, nfolds=3)\n",
    "    result = summary(*result, X, D, y, name='lasso/logistic')\n",
    "    pd.concat([table, result])\n",
    "    \n",
    "    \n",
    "    # Random Forest\n",
    "    rfy = make_pipeline(transformer, RandomForestRegressor(n_estimators=100, min_samples_leaf=10, ccp_alpha=.001))\n",
    "    rfd = make_pipeline(transformer, RandomForestClassifier(n_estimators=100, min_samples_leaf=10, ccp_alpha=.001))\n",
    "    result = dr(X, D, y, rfy, rfy, rfd, nfolds=3)\n",
    "    table = pd.concat([table, summary(*result,  X, D, y, name='random forest')])\n",
    "\n",
    "    # Decision Trees\n",
    "    dtry = make_pipeline(transformer, DecisionTreeRegressor(min_samples_leaf=10, ccp_alpha=.001))\n",
    "    dtrd = make_pipeline(transformer, DecisionTreeClassifier(min_samples_leaf=10, ccp_alpha=.001))\n",
    "    result = dr(X, D, y, dtry, dtry, dtrd, nfolds=3)\n",
    "    table = pd.concat([table, summary(*result,  X, D, y, name='decision tree')])\n",
    "\n",
    "    # Boosted Trees\n",
    "    gbfy = make_pipeline(transformer, GradientBoostingRegressor(max_depth=2, n_iter_no_change=5))\n",
    "    gbfd = make_pipeline(transformer, GradientBoostingClassifier(max_depth=2, n_iter_no_change=5))\n",
    "    result = dr(X, D, y, gbfy, gbfy, gbfd, nfolds=3)\n",
    "    table = pd.concat([table, summary(*result,  X, D, y, name='boosted forest')])\n",
    "\n",
    "    # AutoML\n",
    "#     flamly0 = make_pipeline(transformer, AutoML(time_budget=60, task='regression', early_stop=True,\n",
    "#                                          eval_method='cv', n_splits=3, metric='r2', verbose=0))\n",
    "#     flamly1 = make_pipeline(transformer, AutoML(time_budget=60, task='regression', early_stop=True,\n",
    "#                                          eval_method='cv', n_splits=3, metric='r2', verbose=0))\n",
    "#     flamld = make_pipeline(transformer, AutoML(time_budget=60, task='classification', early_stop=True,\n",
    "#                                                eval_method='cv', n_splits=3, metric='r2', verbose=0))\n",
    "#     flamly0.fit(X[D==0], y[D==0])\n",
    "#     besty0 = make_pipeline(transformer, clone(flamly0[-1].best_model_for_estimator(flamly0[-1].best_estimator)))\n",
    "#     flamly1.fit(X[D==1], y[D==1])\n",
    "#     besty1 = make_pipeline(transformer, clone(flamly1[-1].best_model_for_estimator(flamly1[-1].best_estimator)))\n",
    "#     flamld.fit(X, D)\n",
    "#     bestd = make_pipeline(transformer, clone(flamld[-1].best_model_for_estimator(flamld[-1].best_estimator)))\n",
    "#     result = dr(X, D, y, besty0, besty1, bestd, nfolds=3)\n",
    "#     table = pd.concat([table, summary(*result,  X, D, y, name='automl (semi-cfit)')])\n",
    "\n",
    "    # Stacked semi-crossfit\n",
    "    result = dr_dirty(X, D, y, [lassoy, rfy, dtry, gbfy], [lassoy, rfy, dtry, gbfy], [lgrd, rfd, dtrd, gbfd], nfolds=3)\n",
    "    table = pd.concat([table, summary(*result,  X, D, y, name='stacked (semi-cfit)')])\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57ae0046",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"https://raw.githubusercontent.com/CausalAIBook/MetricsMLNotebooks/main/data/401k.csv\"\n",
    "data = pd.read_csv(file)\n",
    "\n",
    "y = data['net_tfa'].values\n",
    "D = data['e401'].values\n",
    "D2 = data['p401'].values\n",
    "D3 = data['a401'].values\n",
    "X = data.drop(['e401', 'p401', 'a401', 'tw', 'tfa', 'net_tfa', 'tfa_he',\n",
    "               'hval', 'hmort', 'hequity',\n",
    "               'nifa', 'net_nifa', 'net_n401', 'ira',\n",
    "               'dum91', 'icat', 'ecat', 'zhat',\n",
    "               'i1', 'i2', 'i3', 'i4', 'i5', 'i6', 'i7',\n",
    "               'a1', 'a2', 'a3', 'a4', 'a5'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbd4bfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 25% of incomes table, PLM\n",
    "\n",
    "q75 = X['inc'].quantile(.75)\n",
    "keepIndices = X[ X.inc >= q75 ].index\n",
    "X_top25 = X.loc[keepIndices]\n",
    "y_top25 = y[keepIndices]\n",
    "D_top25 = D[keepIndices]\n",
    "\n",
    "q25 = X['inc'].quantile(.25)\n",
    "keepIndices = X[ X.inc <= q25 ].index\n",
    "X_bottom25 = X.loc[keepIndices]\n",
    "y_bottom25 = y[keepIndices]\n",
    "D_bottom25 = D[keepIndices]\n",
    "\n",
    "transformer = FormulaTransformer(\"0 + poly(age, degree=6, raw=True) + poly(inc, degree=8, raw=True) \"\n",
    "                                 \"+ poly(educ, degree=4, raw=True) + poly(fsize, degree=2, raw=True) \"\n",
    "                                 \"+ male + marr + twoearn + db + pira + hown\", array=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d2fc9f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimate</th>\n",
       "      <th>stderr</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>rmse y</th>\n",
       "      <th>rmse D</th>\n",
       "      <th>accuracy D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lasso/logistic</th>\n",
       "      <td>17599.136856</td>\n",
       "      <td>3876.385689</td>\n",
       "      <td>10001.420905</td>\n",
       "      <td>25196.852807</td>\n",
       "      <td>91149.933462</td>\n",
       "      <td>0.482720</td>\n",
       "      <td>0.602662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>17519.141514</td>\n",
       "      <td>3968.317264</td>\n",
       "      <td>9741.239677</td>\n",
       "      <td>25297.043351</td>\n",
       "      <td>94305.894884</td>\n",
       "      <td>0.484873</td>\n",
       "      <td>0.603873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>11358.487068</td>\n",
       "      <td>4075.898655</td>\n",
       "      <td>3369.725705</td>\n",
       "      <td>19347.248431</td>\n",
       "      <td>100253.218084</td>\n",
       "      <td>0.552523</td>\n",
       "      <td>0.529649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boosted forest</th>\n",
       "      <td>18280.803297</td>\n",
       "      <td>3831.720412</td>\n",
       "      <td>10770.631289</td>\n",
       "      <td>25790.975305</td>\n",
       "      <td>95036.967040</td>\n",
       "      <td>0.484491</td>\n",
       "      <td>0.602259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>automl</th>\n",
       "      <td>18065.252873</td>\n",
       "      <td>3895.713823</td>\n",
       "      <td>10429.653780</td>\n",
       "      <td>25700.851967</td>\n",
       "      <td>95298.612633</td>\n",
       "      <td>0.487227</td>\n",
       "      <td>0.587334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stacked (semi-cfit)</th>\n",
       "      <td>18542.731498</td>\n",
       "      <td>3820.501509</td>\n",
       "      <td>11054.548541</td>\n",
       "      <td>26030.914456</td>\n",
       "      <td>90593.733006</td>\n",
       "      <td>0.481634</td>\n",
       "      <td>0.605083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         estimate       stderr         lower         upper  \\\n",
       "lasso/logistic       17599.136856  3876.385689  10001.420905  25196.852807   \n",
       "random forest        17519.141514  3968.317264   9741.239677  25297.043351   \n",
       "decision tree        11358.487068  4075.898655   3369.725705  19347.248431   \n",
       "boosted forest       18280.803297  3831.720412  10770.631289  25790.975305   \n",
       "automl               18065.252873  3895.713823  10429.653780  25700.851967   \n",
       "stacked (semi-cfit)  18542.731498  3820.501509  11054.548541  26030.914456   \n",
       "\n",
       "                            rmse y    rmse D  accuracy D  \n",
       "lasso/logistic        91149.933462  0.482720    0.602662  \n",
       "random forest         94305.894884  0.484873    0.603873  \n",
       "decision tree        100253.218084  0.552523    0.529649  \n",
       "boosted forest        95036.967040  0.484491    0.602259  \n",
       "automl                95298.612633  0.487227    0.587334  \n",
       "stacked (semi-cfit)   90593.733006  0.481634    0.605083  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PLM, top 25% income\n",
    "create_PLM_table(X_top25, D_top25, y_top25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a30ed025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimate</th>\n",
       "      <th>stderr</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>rmse y</th>\n",
       "      <th>rmse D</th>\n",
       "      <th>accuracy D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>17623.308701</td>\n",
       "      <td>3951.243400</td>\n",
       "      <td>9878.871636</td>\n",
       "      <td>25367.745765</td>\n",
       "      <td>96966.742832</td>\n",
       "      <td>0.484563</td>\n",
       "      <td>0.601856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>-34641.313241</td>\n",
       "      <td>48665.421772</td>\n",
       "      <td>-130025.539915</td>\n",
       "      <td>60742.913432</td>\n",
       "      <td>102482.566021</td>\n",
       "      <td>0.551927</td>\n",
       "      <td>0.528035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boosted forest</th>\n",
       "      <td>17446.345653</td>\n",
       "      <td>3860.792434</td>\n",
       "      <td>9879.192483</td>\n",
       "      <td>25013.498824</td>\n",
       "      <td>95083.010746</td>\n",
       "      <td>0.484808</td>\n",
       "      <td>0.594191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stacked (semi-cfit)</th>\n",
       "      <td>17999.370683</td>\n",
       "      <td>3698.084268</td>\n",
       "      <td>10751.125518</td>\n",
       "      <td>25247.615848</td>\n",
       "      <td>90077.014144</td>\n",
       "      <td>0.481897</td>\n",
       "      <td>0.601049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         estimate        stderr          lower         upper  \\\n",
       "random forest        17623.308701   3951.243400    9878.871636  25367.745765   \n",
       "decision tree       -34641.313241  48665.421772 -130025.539915  60742.913432   \n",
       "boosted forest       17446.345653   3860.792434    9879.192483  25013.498824   \n",
       "stacked (semi-cfit)  17999.370683   3698.084268   10751.125518  25247.615848   \n",
       "\n",
       "                            rmse y    rmse D  accuracy D  \n",
       "random forest         96966.742832  0.484563    0.601856  \n",
       "decision tree        102482.566021  0.551927    0.528035  \n",
       "boosted forest        95083.010746  0.484808    0.594191  \n",
       "stacked (semi-cfit)   90077.014144  0.481897    0.601049  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IRM, top 25% income\n",
    "create_IRM_table(X_top25, D_top25, y_top25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a295948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimate</th>\n",
       "      <th>stderr</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>rmse y</th>\n",
       "      <th>rmse D</th>\n",
       "      <th>accuracy D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lasso/logistic</th>\n",
       "      <td>3765.642212</td>\n",
       "      <td>1059.865913</td>\n",
       "      <td>1688.305022</td>\n",
       "      <td>5842.979402</td>\n",
       "      <td>13374.385873</td>\n",
       "      <td>0.358852</td>\n",
       "      <td>0.846836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>4011.284566</td>\n",
       "      <td>1077.508200</td>\n",
       "      <td>1899.368493</td>\n",
       "      <td>6123.200638</td>\n",
       "      <td>13476.072451</td>\n",
       "      <td>0.344080</td>\n",
       "      <td>0.844015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>3642.741909</td>\n",
       "      <td>1108.190652</td>\n",
       "      <td>1470.688231</td>\n",
       "      <td>5814.795586</td>\n",
       "      <td>15253.669052</td>\n",
       "      <td>0.376277</td>\n",
       "      <td>0.809351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boosted forest</th>\n",
       "      <td>4187.387308</td>\n",
       "      <td>1112.714411</td>\n",
       "      <td>2006.467063</td>\n",
       "      <td>6368.307553</td>\n",
       "      <td>13474.682391</td>\n",
       "      <td>0.343599</td>\n",
       "      <td>0.846433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>automl</th>\n",
       "      <td>4054.580938</td>\n",
       "      <td>1038.486054</td>\n",
       "      <td>2019.148272</td>\n",
       "      <td>6090.013605</td>\n",
       "      <td>13302.179712</td>\n",
       "      <td>0.347103</td>\n",
       "      <td>0.841596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stacked (semi-cfit)</th>\n",
       "      <td>3999.230999</td>\n",
       "      <td>1082.822361</td>\n",
       "      <td>1876.899172</td>\n",
       "      <td>6121.562827</td>\n",
       "      <td>13232.706388</td>\n",
       "      <td>0.343444</td>\n",
       "      <td>0.844015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        estimate       stderr        lower        upper  \\\n",
       "lasso/logistic       3765.642212  1059.865913  1688.305022  5842.979402   \n",
       "random forest        4011.284566  1077.508200  1899.368493  6123.200638   \n",
       "decision tree        3642.741909  1108.190652  1470.688231  5814.795586   \n",
       "boosted forest       4187.387308  1112.714411  2006.467063  6368.307553   \n",
       "automl               4054.580938  1038.486054  2019.148272  6090.013605   \n",
       "stacked (semi-cfit)  3999.230999  1082.822361  1876.899172  6121.562827   \n",
       "\n",
       "                           rmse y    rmse D  accuracy D  \n",
       "lasso/logistic       13374.385873  0.358852    0.846836  \n",
       "random forest        13476.072451  0.344080    0.844015  \n",
       "decision tree        15253.669052  0.376277    0.809351  \n",
       "boosted forest       13474.682391  0.343599    0.846433  \n",
       "automl               13302.179712  0.347103    0.841596  \n",
       "stacked (semi-cfit)  13232.706388  0.343444    0.844015  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PLM, bottom 25% income\n",
    "create_PLM_table(X_bottom25, D_bottom25, y_bottom25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8180935b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimate</th>\n",
       "      <th>stderr</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>rmse y</th>\n",
       "      <th>rmse D</th>\n",
       "      <th>accuracy D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>4268.571973</td>\n",
       "      <td>988.706938</td>\n",
       "      <td>2330.706374</td>\n",
       "      <td>6206.437572</td>\n",
       "      <td>13533.730752</td>\n",
       "      <td>0.344661</td>\n",
       "      <td>0.844418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>10506.846296</td>\n",
       "      <td>6065.384115</td>\n",
       "      <td>-1381.306568</td>\n",
       "      <td>22394.999161</td>\n",
       "      <td>15081.235395</td>\n",
       "      <td>0.376161</td>\n",
       "      <td>0.809351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boosted forest</th>\n",
       "      <td>4781.028185</td>\n",
       "      <td>996.476801</td>\n",
       "      <td>2827.933655</td>\n",
       "      <td>6734.122715</td>\n",
       "      <td>13717.897013</td>\n",
       "      <td>0.344723</td>\n",
       "      <td>0.844821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stacked (semi-cfit)</th>\n",
       "      <td>4393.730503</td>\n",
       "      <td>953.923087</td>\n",
       "      <td>2524.041253</td>\n",
       "      <td>6263.419754</td>\n",
       "      <td>13201.983715</td>\n",
       "      <td>0.342357</td>\n",
       "      <td>0.847642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         estimate       stderr        lower         upper  \\\n",
       "random forest         4268.571973   988.706938  2330.706374   6206.437572   \n",
       "decision tree        10506.846296  6065.384115 -1381.306568  22394.999161   \n",
       "boosted forest        4781.028185   996.476801  2827.933655   6734.122715   \n",
       "stacked (semi-cfit)   4393.730503   953.923087  2524.041253   6263.419754   \n",
       "\n",
       "                           rmse y    rmse D  accuracy D  \n",
       "random forest        13533.730752  0.344661    0.844418  \n",
       "decision tree        15081.235395  0.376161    0.809351  \n",
       "boosted forest       13717.897013  0.344723    0.844821  \n",
       "stacked (semi-cfit)  13201.983715  0.342357    0.847642  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PLM, bottom 25% income\n",
    "create_IRM_table(X_bottom25, D_bottom25, y_bottom25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eee0aa4",
   "metadata": {},
   "source": [
    "The estimates are much higher for the top 25% of the income distribution compared ot the bottom 25%, indicating heterogeneity on the effect of 401k with respect to income. This is likely because people with higher incomes are more likely to participate in their 401k, and add more to their 401k each month. As a result, their additional accumulated assets through their 401k is higher over the course of their lifetime. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a9739e",
   "metadata": {},
   "source": [
    "### Part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2ab58ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dml_cf_best(X, D, y, modely_list, modeld_list, *, nfolds, classifier=False):\n",
    "    '''\n",
    "    DML for the Partially Linear Model setting with semi-cross-fitting, without stacking\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    X: the controls\n",
    "    D: the treatment\n",
    "    y: the outcome\n",
    "    modely: the ML model for predicting the outcome y\n",
    "    modeld: the ML model for predicting the treatment D\n",
    "    stacker: model used to aggregate predictions of each of the base models\n",
    "    nfolds: the number of folds in cross-fitting\n",
    "    classifier: bool, whether the modeld is a classifier or a regressor\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    point: the point estimate of the treatment effect of D on y\n",
    "    stderr: the standard error of the treatment effect\n",
    "    bestmodel_yhats: the cross-fitted predictions for the outcome y\n",
    "    bestmodel_Dhats: the cross-fitted predictions for the treatment D\n",
    "    resy: the outcome residuals\n",
    "    resD: the treatment residuals\n",
    "    epsilon: the final residual-on-residual OLS regression residual\n",
    "    '''\n",
    "    # construct out-of-fold predictions for each model\n",
    "    cv = KFold(n_splits=nfolds, shuffle=True, random_state=123)\n",
    "    yhats = np.array([cross_val_predict(modely, X, y, cv=cv, n_jobs=-1) for modely in modely_list]).T\n",
    "    if classifier:\n",
    "        Dhats = np.array([cross_val_predict(modeld, X, D, cv=cv, method='predict_proba', n_jobs=-1)[:, 1]\n",
    "                         for modeld in modeld_list]).T\n",
    "    else:\n",
    "        Dhats = np.array([cross_val_predict(modeld, X, D, cv=cv, n_jobs=-1) for modeld in modeld_list]).T\n",
    "        \n",
    "    # calculate MSEs\n",
    "    yhats_mses = [np.mean((yhats[:, modely] - y)**2) for modely in range(0, len(modely_list))]\n",
    "    Dhats_mses = [np.mean((Dhats[:, modeld] - D)**2) for modeld in range(0, len(modeld_list))]\n",
    "    \n",
    "    # use yhats and Dhats from best model\n",
    "    bestmodel_yhats = yhats[:, np.argmin(yhats_mses)]\n",
    "    bestmodel_Dhats = Dhats[:, np.argmin(Dhats_mses)]\n",
    "    \n",
    "    # get ATE\n",
    "    resy = y - bestmodel_yhats\n",
    "    resD = D - bestmodel_Dhats\n",
    "    # go with the stacked residuals\n",
    "    point = np.mean(resy * resD) / np.mean(resD**2)\n",
    "    epsilon = resy - point * resD\n",
    "    var = np.mean(epsilon**2 * resD**2) / np.mean(resD**2)**2\n",
    "    stderr = np.sqrt(var / X.shape[0])\n",
    "    \n",
    "    return point, stderr, bestmodel_yhats, bestmodel_Dhats, resy, resD, epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d082e4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dr_cf_best(X, D, y, modely0_list, modely1_list, modeld_list, *, trimming=0.01, nfolds):\n",
    "    '''\n",
    "    DML for the Interactive Regression Model setting (Doubly Robust Learning)\n",
    "    with cross-fitting, without stacking\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    X: the controls\n",
    "    D: the treatment\n",
    "    y: the outcome\n",
    "    modely_list: list of ML models for predicting the outcome y\n",
    "    modeld_list: list of ML models for predicting the treatment D\n",
    "    stacker: model used to aggregate predictions of each of the base models\n",
    "    trimming: threshold below which to trim propensities\n",
    "    nfolds: the number of folds in cross-fitting\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    point: the point estimate of the treatment effect of D on y\n",
    "    stderr: the standard error of the treatment effect\n",
    "    yhat: the cross-fitted predictions for the outcome y\n",
    "    bestmodel_Dhats: the cross-fitted predictions for the outcome D\n",
    "    resy: the outcome residuals\n",
    "    resD: the treatment residuals\n",
    "    drhat: the doubly robust quantity for each sample\n",
    "    '''\n",
    "    cv = KFold(n_splits=nfolds, shuffle=True, random_state=123)\n",
    "\n",
    "    # we will fit a model E[Y| D, X] by fitting a separate model for D==0\n",
    "    # and a separate model for D==1. We do that for each model type in modely_list\n",
    "    yhats0, yhats1 = np.zeros((y.shape[0], len(modely0_list))), np.zeros((y.shape[0], len(modely1_list)))\n",
    "    for train, test in cv.split(X, y):\n",
    "        for it, modely0 in enumerate(modely0_list):\n",
    "            yhats0[test, it] = clone(modely0).fit(X.iloc[train][D[train]==0], y[train][D[train]==0]).predict(X.iloc[test])\n",
    "        for it, modely1 in enumerate(modely1_list):\n",
    "            yhats1[test, it] = clone(modely1).fit(X.iloc[train][D[train]==1], y[train][D[train]==1]).predict(X.iloc[test])\n",
    "\n",
    "    # propensity scores\n",
    "    Dhats = np.array([cross_val_predict(modeld, X, D, cv=cv, method='predict_proba', n_jobs=-1)[:, 1]\n",
    "                     for modeld in modeld_list]).T\n",
    "    \n",
    "    # calculate MSEs\n",
    "    y0hats_mses = [np.mean((yhats0[D==0][:, modely] - y[D==0])**2) for modely in range(0, len(modely0_list))]\n",
    "    y1hats_mses = [np.mean((yhats1[D==1][:, modely] - y[D==1])**2) for modely in range(0, len(modely1_list))]\n",
    "    Dhats_mses = [np.mean((Dhats[:, modeld] - D)**2) for modeld in range(0, len(modeld_list))]    \n",
    "    \n",
    "    # use yhats and Dhats from best model\n",
    "    bestmodel_y0hats = yhats0[:, np.argmin(y0hats_mses)]\n",
    "    bestmodel_y1hats = yhats1[:, np.argmin(y1hats_mses)]\n",
    "    bestmodel_Dhats = Dhats[:, np.argmin(Dhats_mses)]\n",
    "    \n",
    "    # prediction for observed treatment using the best model\n",
    "    yhat = bestmodel_y0hats * (1 - D) + bestmodel_y1hats * D \n",
    "    \n",
    "\n",
    "    # trim propensities\n",
    "    bestmodel_Dhats = np.clip(bestmodel_Dhats, trimming, 1 - trimming)\n",
    "\n",
    "    # doubly robust quantity for every sample\n",
    "    drhat = bestmodel_y1hats - bestmodel_y0hats + (y - yhat) * (D/bestmodel_Dhats - (1 - D)/(1 - bestmodel_Dhats))\n",
    "    point = np.mean(drhat)\n",
    "    var = np.var(drhat)\n",
    "    stderr = np.sqrt(var / X.shape[0])\n",
    "    return point, stderr, yhat, bestmodel_Dhats, y - yhat, D - bestmodel_Dhats, drhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5134fb83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimate</th>\n",
       "      <th>stderr</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>rmse y</th>\n",
       "      <th>rmse D</th>\n",
       "      <th>accuracy D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>double lasso</th>\n",
       "      <td>8914.299159</td>\n",
       "      <td>1289.335778</td>\n",
       "      <td>6387.201034</td>\n",
       "      <td>11441.397284</td>\n",
       "      <td>54111.994234</td>\n",
       "      <td>0.443826</td>\n",
       "      <td>0.688048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasso/logistic</th>\n",
       "      <td>8494.171826</td>\n",
       "      <td>1292.180346</td>\n",
       "      <td>5961.498348</td>\n",
       "      <td>11026.845303</td>\n",
       "      <td>54111.994234</td>\n",
       "      <td>0.444247</td>\n",
       "      <td>0.686233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>8948.523137</td>\n",
       "      <td>1365.770525</td>\n",
       "      <td>6271.612907</td>\n",
       "      <td>11625.433367</td>\n",
       "      <td>55131.431552</td>\n",
       "      <td>0.444534</td>\n",
       "      <td>0.691377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>9354.674857</td>\n",
       "      <td>1478.080231</td>\n",
       "      <td>6457.637605</td>\n",
       "      <td>12251.712109</td>\n",
       "      <td>59843.566636</td>\n",
       "      <td>0.447080</td>\n",
       "      <td>0.678467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boosted forest</th>\n",
       "      <td>9287.725203</td>\n",
       "      <td>1393.387694</td>\n",
       "      <td>6556.685323</td>\n",
       "      <td>12018.765083</td>\n",
       "      <td>56237.867900</td>\n",
       "      <td>0.444240</td>\n",
       "      <td>0.690872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AutoML</th>\n",
       "      <td>9282.807506</td>\n",
       "      <td>1367.186950</td>\n",
       "      <td>6603.121083</td>\n",
       "      <td>11962.493929</td>\n",
       "      <td>55597.261019</td>\n",
       "      <td>0.444929</td>\n",
       "      <td>0.689259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stacked (semi-cfit)</th>\n",
       "      <td>8958.135007</td>\n",
       "      <td>1307.606453</td>\n",
       "      <td>6395.226360</td>\n",
       "      <td>11521.043655</td>\n",
       "      <td>53897.076928</td>\n",
       "      <td>0.443180</td>\n",
       "      <td>0.691881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best (semi-cfit)</th>\n",
       "      <td>8889.630317</td>\n",
       "      <td>1319.102890</td>\n",
       "      <td>6304.188653</td>\n",
       "      <td>11475.071981</td>\n",
       "      <td>54111.994234</td>\n",
       "      <td>0.443922</td>\n",
       "      <td>0.692789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        estimate       stderr        lower         upper  \\\n",
       "double lasso         8914.299159  1289.335778  6387.201034  11441.397284   \n",
       "lasso/logistic       8494.171826  1292.180346  5961.498348  11026.845303   \n",
       "random forest        8948.523137  1365.770525  6271.612907  11625.433367   \n",
       "decision tree        9354.674857  1478.080231  6457.637605  12251.712109   \n",
       "boosted forest       9287.725203  1393.387694  6556.685323  12018.765083   \n",
       "AutoML               9282.807506  1367.186950  6603.121083  11962.493929   \n",
       "stacked (semi-cfit)  8958.135007  1307.606453  6395.226360  11521.043655   \n",
       "best (semi-cfit)     8889.630317  1319.102890  6304.188653  11475.071981   \n",
       "\n",
       "                           rmse y    rmse D  accuracy D  \n",
       "double lasso         54111.994234  0.443826    0.688048  \n",
       "lasso/logistic       54111.994234  0.444247    0.686233  \n",
       "random forest        55131.431552  0.444534    0.691377  \n",
       "decision tree        59843.566636  0.447080    0.678467  \n",
       "boosted forest       56237.867900  0.444240    0.690872  \n",
       "AutoML               55597.261019  0.444929    0.689259  \n",
       "stacked (semi-cfit)  53897.076928  0.443180    0.691881  \n",
       "best (semi-cfit)     54111.994234  0.443922    0.692789  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DML table on full data, including best model function implemented above\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "lassoy = make_pipeline(transformer, StandardScaler(), LassoCV(cv=cv))\n",
    "lassod = make_pipeline(transformer, StandardScaler(), LassoCV(cv=cv))\n",
    "result = dml(X, D, y, lassoy, lassod, nfolds=3)\n",
    "table = summary(*result, X, D, y, name='double lasso')\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "lassoy = make_pipeline(transformer, StandardScaler(), LassoCV(cv=cv))\n",
    "lgrd = make_pipeline(transformer, StandardScaler(), LogisticRegressionCV(cv=cv))\n",
    "result = dml(X, D, y, lassoy, lgrd, nfolds=3, classifier=True)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='lasso/logistic')])\n",
    "\n",
    "rfy = make_pipeline(transformer, RandomForestRegressor(n_estimators=100, min_samples_leaf=10, ccp_alpha=.001))\n",
    "rfd = make_pipeline(transformer, RandomForestClassifier(n_estimators=100, min_samples_leaf=10, ccp_alpha=.001))\n",
    "result = dml(X, D, y, rfy, rfd, nfolds=3, classifier=True)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='random forest')])\n",
    "\n",
    "dtry = make_pipeline(transformer, DecisionTreeRegressor(min_samples_leaf=10, ccp_alpha=.001))\n",
    "dtrd = make_pipeline(transformer, DecisionTreeClassifier(min_samples_leaf=10, ccp_alpha=.001))\n",
    "result = dml(X, D, y, dtry, dtrd, nfolds=3, classifier=True)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='decision tree')])\n",
    "\n",
    "gbfy = make_pipeline(transformer, GradientBoostingRegressor(max_depth=2, n_iter_no_change=5))\n",
    "gbfd = make_pipeline(transformer, GradientBoostingClassifier(max_depth=2, n_iter_no_change=5))\n",
    "result = dml(X, D, y, gbfy, gbfd, nfolds=3, classifier=True)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='boosted forest')])\n",
    "\n",
    "flamly = make_pipeline(transformer, AutoML(time_budget=100, task='regression', early_stop=True,\n",
    "                                    eval_method='cv', n_splits=3, metric='r2', verbose=3))\n",
    "flamld = make_pipeline(transformer, AutoML(time_budget=100, task='classification', early_stop=True,\n",
    "                                           eval_method='cv', n_splits=3, metric='r2', verbose=3))\n",
    "result = dml(X, D, y, flamly, flamld, nfolds=3, classifier=True)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='AutoML')])\n",
    "\n",
    "# flamly = make_pipeline(transformer, AutoML(time_budget=100, task='regression', early_stop=True,\n",
    "#                                     eval_method='cv', n_splits=3, metric='r2', verbose=0))\n",
    "# flamld = make_pipeline(transformer, AutoML(time_budget=100, task='classification', early_stop=True,\n",
    "#                                            eval_method='cv', n_splits=3, metric='r2', verbose=0))\n",
    "# flamly.fit(X, y)\n",
    "# besty = make_pipeline(transformer, clone(flamly[-1].best_model_for_estimator(flamly[-1].best_estimator)))\n",
    "# flamld.fit(X, D)\n",
    "# bestd = make_pipeline(transformer, clone(flamld[-1].best_model_for_estimator(flamld[-1].best_estimator)))\n",
    "# result = dml(X, D, y, besty, bestd, nfolds=3, classifier=True)\n",
    "# table = pd.concat([table, summary(*result,  X, D, y, name='automl (semi-cfit)')])\n",
    "\n",
    "result = dml_dirty(X, D, y, [lassoy, rfy, dtry, gbfy], [lgrd, rfd, dtrd, gbfd],\n",
    "                   nfolds=3, classifier=True)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='stacked (semi-cfit)')])\n",
    "\n",
    "result = dml_cf_best(X, D, y, [lassoy, rfy, dtry, gbfy], [lgrd, rfd, dtrd, gbfd],\n",
    "                   nfolds=3, classifier=True)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='best (semi-cfit)')])\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03482c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimate</th>\n",
       "      <th>stderr</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>rmse y</th>\n",
       "      <th>rmse D</th>\n",
       "      <th>accuracy D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lasso/logistic</th>\n",
       "      <td>2535.427991</td>\n",
       "      <td>5434.603246</td>\n",
       "      <td>-8116.394371</td>\n",
       "      <td>13187.250352</td>\n",
       "      <td>54023.763725</td>\n",
       "      <td>0.444247</td>\n",
       "      <td>0.686233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>7819.960558</td>\n",
       "      <td>1162.348040</td>\n",
       "      <td>5541.758401</td>\n",
       "      <td>10098.162716</td>\n",
       "      <td>55489.789340</td>\n",
       "      <td>0.444623</td>\n",
       "      <td>0.691074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>7077.394356</td>\n",
       "      <td>1290.400732</td>\n",
       "      <td>4548.208921</td>\n",
       "      <td>9606.579790</td>\n",
       "      <td>60264.954815</td>\n",
       "      <td>0.447080</td>\n",
       "      <td>0.678467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boosted forest</th>\n",
       "      <td>8553.342176</td>\n",
       "      <td>1158.530304</td>\n",
       "      <td>6282.622781</td>\n",
       "      <td>10824.061572</td>\n",
       "      <td>54960.051588</td>\n",
       "      <td>0.444021</td>\n",
       "      <td>0.691276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stacked (semi-cfit)</th>\n",
       "      <td>7616.709741</td>\n",
       "      <td>1139.060553</td>\n",
       "      <td>5384.151058</td>\n",
       "      <td>9849.268424</td>\n",
       "      <td>53836.232349</td>\n",
       "      <td>0.443248</td>\n",
       "      <td>0.689864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best (semi-cfit)</th>\n",
       "      <td>7873.570587</td>\n",
       "      <td>1129.950106</td>\n",
       "      <td>5658.868379</td>\n",
       "      <td>10088.272795</td>\n",
       "      <td>54023.763725</td>\n",
       "      <td>0.444186</td>\n",
       "      <td>0.692789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        estimate       stderr        lower         upper  \\\n",
       "lasso/logistic       2535.427991  5434.603246 -8116.394371  13187.250352   \n",
       "random forest        7819.960558  1162.348040  5541.758401  10098.162716   \n",
       "decision tree        7077.394356  1290.400732  4548.208921   9606.579790   \n",
       "boosted forest       8553.342176  1158.530304  6282.622781  10824.061572   \n",
       "stacked (semi-cfit)  7616.709741  1139.060553  5384.151058   9849.268424   \n",
       "best (semi-cfit)     7873.570587  1129.950106  5658.868379  10088.272795   \n",
       "\n",
       "                           rmse y    rmse D  accuracy D  \n",
       "lasso/logistic       54023.763725  0.444247    0.686233  \n",
       "random forest        55489.789340  0.444623    0.691074  \n",
       "decision tree        60264.954815  0.447080    0.678467  \n",
       "boosted forest       54960.051588  0.444021    0.691276  \n",
       "stacked (semi-cfit)  53836.232349  0.443248    0.689864  \n",
       "best (semi-cfit)     54023.763725  0.444186    0.692789  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DR table on full data, including best model function implemented above\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "lassoy = make_pipeline(transformer, StandardScaler(), LassoCV(cv=cv))\n",
    "lgrd = make_pipeline(transformer, StandardScaler(), LogisticRegressionCV(cv=cv))\n",
    "result = dr(X, D, y, lassoy, lassoy, lgrd, nfolds=3)\n",
    "table = summary(*result, X, D, y, name='lasso/logistic')\n",
    "\n",
    "rfy = make_pipeline(transformer, RandomForestRegressor(n_estimators=100, min_samples_leaf=10, ccp_alpha=.001))\n",
    "rfd = make_pipeline(transformer, RandomForestClassifier(n_estimators=100, min_samples_leaf=10, ccp_alpha=.001))\n",
    "result = dr(X, D, y, rfy, rfy, rfd, nfolds=3)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='random forest')])\n",
    "\n",
    "dtry = make_pipeline(transformer, DecisionTreeRegressor(min_samples_leaf=10, ccp_alpha=.001))\n",
    "dtrd = make_pipeline(transformer, DecisionTreeClassifier(min_samples_leaf=10, ccp_alpha=.001))\n",
    "result = dr(X, D, y, dtry, dtry, dtrd, nfolds=3)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='decision tree')])\n",
    "\n",
    "gbfy = make_pipeline(transformer, GradientBoostingRegressor(max_depth=2, n_iter_no_change=5))\n",
    "gbfd = make_pipeline(transformer, GradientBoostingClassifier(max_depth=2, n_iter_no_change=5))\n",
    "result = dr(X, D, y, gbfy, gbfy, gbfd, nfolds=3)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='boosted forest')])\n",
    "\n",
    "# flamly0 = make_pipeline(transformer, AutoML(time_budget=60, task='regression', early_stop=True,\n",
    "#                                      eval_method='cv', n_splits=3, metric='r2', verbose=0))\n",
    "# flamly1 = make_pipeline(transformer, AutoML(time_budget=60, task='regression', early_stop=True,\n",
    "#                                      eval_method='cv', n_splits=3, metric='r2', verbose=0))\n",
    "# flamld = make_pipeline(transformer, AutoML(time_budget=60, task='classification', early_stop=True,\n",
    "#                                            eval_method='cv', n_splits=3, metric='r2', verbose=0))\n",
    "# flamly0.fit(X[D==0], y[D==0])\n",
    "# besty0 = make_pipeline(transformer, clone(flamly0[-1].best_model_for_estimator(flamly0[-1].best_estimator)))\n",
    "# flamly1.fit(X[D==1], y[D==1])\n",
    "# besty1 = make_pipeline(transformer, clone(flamly1[-1].best_model_for_estimator(flamly1[-1].best_estimator)))\n",
    "# flamld.fit(X, D)\n",
    "# bestd = make_pipeline(transformer, clone(flamld[-1].best_model_for_estimator(flamld[-1].best_estimator)))\n",
    "# result = dr(X, D, y, besty0, besty1, bestd, nfolds=3)\n",
    "# table = pd.concat([table, summary(*result,  X, D, y, name='automl (semi-cfit)')])\n",
    "\n",
    "result = dr_dirty(X, D, y, [lassoy, rfy, dtry, gbfy], [lassoy, rfy, dtry, gbfy], [lgrd, rfd, dtrd, gbfd], nfolds=3)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='stacked (semi-cfit)')])\n",
    "\n",
    "result = dr_cf_best(X, D, y, [lassoy, rfy, dtry, gbfy], [lassoy, rfy, dtry, gbfy], [lgrd, rfd, dtrd, gbfd], nfolds=3)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='best (semi-cfit)')])\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa2bffe",
   "metadata": {},
   "source": [
    "### Part c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "212f6667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using EconML\n",
    "\n",
    "from econml.dml import LinearDML\n",
    "from econml.dr import LinearDRLearner\n",
    "from econml.utilities import SeparateModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd4a03d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = StandardScaler().fit_transform(transformer.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ced27e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient Results:  X is None, please call intercept_inference to learn the constant!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>CATE Intercept Results</caption>\n",
       "<tr>\n",
       "         <td></td>        <th>point_estimate</th>  <th>stderr</th>  <th>zstat</th> <th>pvalue</th> <th>ci_lower</th> <th>ci_upper</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cate_intercept</th>    <td>8184.146</td>    <td>1350.077</td> <td>6.062</td>   <td>0.0</td>  <td>5538.044</td> <td>10830.248</td>\n",
       "</tr>\n",
       "</table><br/><br/><sub>A linear parametric conditional average treatment effect (CATE) model was fitted:<br/>$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$<br/>where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:<br/>$\\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$<br/>Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>"
      ],
      "text/plain": [
       "<class 'econml.utilities.Summary'>\n",
       "\"\"\"\n",
       "                        CATE Intercept Results                        \n",
       "======================================================================\n",
       "               point_estimate  stderr  zstat pvalue ci_lower  ci_upper\n",
       "----------------------------------------------------------------------\n",
       "cate_intercept       8184.146 1350.077 6.062    0.0 5538.044 10830.248\n",
       "----------------------------------------------------------------------\n",
       "\n",
       "<sub>A linear parametric conditional average treatment effect (CATE) model was fitted:\n",
       "$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$\n",
       "where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:\n",
       "$\\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$\n",
       "Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>\n",
       "\"\"\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "rfml = LinearDML(model_y=RandomForestRegressor(n_estimators=100, min_samples_leaf=10, ccp_alpha=.001), \n",
    "                 model_t=RandomForestClassifier(n_estimators=100, min_samples_leaf=10, ccp_alpha=.001),\n",
    "                 cv=3, discrete_treatment=True, random_state=123).fit(y, D, W=W)\n",
    "rfml.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08b9fd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient Results:  X is None, please call intercept_inference to learn the constant!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>CATE Intercept Results</caption>\n",
       "<tr>\n",
       "         <td></td>        <th>point_estimate</th>  <th>stderr</th>  <th>zstat</th> <th>pvalue</th> <th>ci_lower</th> <th>ci_upper</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cate_intercept</th>     <td>8713.87</td>    <td>1426.973</td> <td>6.107</td>   <td>0.0</td>  <td>5917.055</td> <td>11510.685</td>\n",
       "</tr>\n",
       "</table><br/><br/><sub>A linear parametric conditional average treatment effect (CATE) model was fitted:<br/>$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$<br/>where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:<br/>$\\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$<br/>Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>"
      ],
      "text/plain": [
       "<class 'econml.utilities.Summary'>\n",
       "\"\"\"\n",
       "                        CATE Intercept Results                        \n",
       "======================================================================\n",
       "               point_estimate  stderr  zstat pvalue ci_lower  ci_upper\n",
       "----------------------------------------------------------------------\n",
       "cate_intercept        8713.87 1426.973 6.107    0.0 5917.055 11510.685\n",
       "----------------------------------------------------------------------\n",
       "\n",
       "<sub>A linear parametric conditional average treatment effect (CATE) model was fitted:\n",
       "$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$\n",
       "where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:\n",
       "$\\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$\n",
       "Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>\n",
       "\"\"\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient Boosted Tree\n",
    "\n",
    "gbt = LinearDML(model_y=GradientBoostingRegressor(max_depth=5, n_iter_no_change=10), \n",
    "                model_t=GradientBoostingRegressor(max_depth=5, n_iter_no_change=10),\n",
    "                cv=3, discrete_treatment=True, random_state=123).fit(y, D, W=W)\n",
    "gbt.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78e00a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient Results:  X is None, please call intercept_inference to learn the constant!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>CATE Intercept Results</caption>\n",
       "<tr>\n",
       "         <td></td>        <th>point_estimate</th>  <th>stderr</th>  <th>zstat</th> <th>pvalue</th> <th>ci_lower</th> <th>ci_upper</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cate_intercept</th>    <td>8598.567</td>    <td>1417.949</td> <td>6.064</td>   <td>0.0</td>  <td>5819.438</td> <td>11377.697</td>\n",
       "</tr>\n",
       "</table><br/><br/><sub>A linear parametric conditional average treatment effect (CATE) model was fitted:<br/>$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$<br/>where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:<br/>$\\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$<br/>Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>"
      ],
      "text/plain": [
       "<class 'econml.utilities.Summary'>\n",
       "\"\"\"\n",
       "                        CATE Intercept Results                        \n",
       "======================================================================\n",
       "               point_estimate  stderr  zstat pvalue ci_lower  ci_upper\n",
       "----------------------------------------------------------------------\n",
       "cate_intercept       8598.567 1417.949 6.064    0.0 5819.438 11377.697\n",
       "----------------------------------------------------------------------\n",
       "\n",
       "<sub>A linear parametric conditional average treatment effect (CATE) model was fitted:\n",
       "$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$\n",
       "where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:\n",
       "$\\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$\n",
       "Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>\n",
       "\"\"\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "\n",
    "dt = LinearDML(model_y=DecisionTreeRegressor(min_samples_leaf=10, ccp_alpha=.001), \n",
    "               model_t=DecisionTreeRegressor(min_samples_leaf=10, ccp_alpha=.001),\n",
    "               cv=3, discrete_treatment=True, random_state=123).fit(y, D, W=W)\n",
    "\n",
    "dt.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fad0a3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient Results:  X is None, please call intercept_inference to learn the constant!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>CATE Intercept Results</caption>\n",
       "<tr>\n",
       "         <td></td>        <th>point_estimate</th>  <th>stderr</th>  <th>zstat</th> <th>pvalue</th> <th>ci_lower</th> <th>ci_upper</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cate_intercept</th>    <td>7508.136</td>    <td>1137.421</td> <td>6.601</td>   <td>0.0</td>  <td>5278.832</td>  <td>9737.44</td>\n",
       "</tr>\n",
       "</table><br/><br/><sub>A linear parametric conditional average treatment effect (CATE) model was fitted:<br/>$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$<br/>where $T$ is the one-hot-encoding of the discrete treatment and for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:<br/>$\\Theta_{ij}(X) = \\phi(X)' coef_{ij} + cate\\_intercept_{ij}$<br/>where $\\phi(X)$ is the output of the `featurizer` or $X$ if `featurizer`=None. Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and the designated treatment $j$ passed to summary. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>"
      ],
      "text/plain": [
       "<class 'econml.utilities.Summary'>\n",
       "\"\"\"\n",
       "                        CATE Intercept Results                       \n",
       "=====================================================================\n",
       "               point_estimate  stderr  zstat pvalue ci_lower ci_upper\n",
       "---------------------------------------------------------------------\n",
       "cate_intercept       7508.136 1137.421 6.601    0.0 5278.832  9737.44\n",
       "---------------------------------------------------------------------\n",
       "\n",
       "<sub>A linear parametric conditional average treatment effect (CATE) model was fitted:\n",
       "$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$\n",
       "where $T$ is the one-hot-encoding of the discrete treatment and for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:\n",
       "$\\Theta_{ij}(X) = \\phi(X)' coef_{ij} + cate\\_intercept_{ij}$\n",
       "where $\\phi(X)$ is the output of the `featurizer` or $X$ if `featurizer`=None. Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and the designated treatment $j$ passed to summary. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>\n",
       "\"\"\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Doubly Robust Random Forest\n",
    "\n",
    "drrf = LinearDRLearner(\n",
    "            model_regression=SeparateModel(\n",
    "                RandomForestRegressor(n_estimators=100, min_samples_leaf=10, ccp_alpha=.001), \n",
    "                RandomForestRegressor(n_estimators=100, min_samples_leaf=10, ccp_alpha=.001)),\n",
    "            model_propensity=RandomForestClassifier(n_estimators=100, min_samples_leaf=10, ccp_alpha=.001),\n",
    "            cv=3, min_propensity=0.01, random_state=123).fit(y, D, W=W)\n",
    "\n",
    "drrf.summary(T=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83842758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient Results:  X is None, please call intercept_inference to learn the constant!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>CATE Intercept Results</caption>\n",
       "<tr>\n",
       "         <td></td>        <th>point_estimate</th>  <th>stderr</th>  <th>zstat</th> <th>pvalue</th> <th>ci_lower</th> <th>ci_upper</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cate_intercept</th>    <td>7757.003</td>    <td>1217.821</td> <td>6.37</td>    <td>0.0</td>  <td>5370.118</td> <td>10143.888</td>\n",
       "</tr>\n",
       "</table><br/><br/><sub>A linear parametric conditional average treatment effect (CATE) model was fitted:<br/>$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$<br/>where $T$ is the one-hot-encoding of the discrete treatment and for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:<br/>$\\Theta_{ij}(X) = \\phi(X)' coef_{ij} + cate\\_intercept_{ij}$<br/>where $\\phi(X)$ is the output of the `featurizer` or $X$ if `featurizer`=None. Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and the designated treatment $j$ passed to summary. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>"
      ],
      "text/plain": [
       "<class 'econml.utilities.Summary'>\n",
       "\"\"\"\n",
       "                        CATE Intercept Results                        \n",
       "======================================================================\n",
       "               point_estimate  stderr  zstat pvalue ci_lower  ci_upper\n",
       "----------------------------------------------------------------------\n",
       "cate_intercept       7757.003 1217.821  6.37    0.0 5370.118 10143.888\n",
       "----------------------------------------------------------------------\n",
       "\n",
       "<sub>A linear parametric conditional average treatment effect (CATE) model was fitted:\n",
       "$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$\n",
       "where $T$ is the one-hot-encoding of the discrete treatment and for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:\n",
       "$\\Theta_{ij}(X) = \\phi(X)' coef_{ij} + cate\\_intercept_{ij}$\n",
       "where $\\phi(X)$ is the output of the `featurizer` or $X$ if `featurizer`=None. Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and the designated treatment $j$ passed to summary. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>\n",
       "\"\"\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Doubly Robust Gradient Boosted Tree\n",
    "\n",
    "drgbt = LinearDRLearner(\n",
    "            model_regression=SeparateModel(\n",
    "                GradientBoostingRegressor(max_depth=5, n_iter_no_change=10), \n",
    "                GradientBoostingRegressor(max_depth=5, n_iter_no_change=10)),\n",
    "            model_propensity=GradientBoostingClassifier(max_depth=5, n_iter_no_change=10),\n",
    "            cv=3, min_propensity=0.01, random_state=123).fit(y, D, W=W)\n",
    "\n",
    "drgbt.summary(T=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8cc83df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using DoubleML\n",
    "\n",
    "import doubleml as dml\n",
    "from doubleml import DoubleMLData\n",
    "dml_data = DoubleMLData.from_arrays(W, y, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b54af3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== DoubleMLPLR Object ==================\n",
      "\n",
      "------------------ Data summary      ------------------\n",
      "Outcome variable: y\n",
      "Treatment variable(s): ['d']\n",
      "Covariates: ['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12', 'X13', 'X14', 'X15', 'X16', 'X17', 'X18', 'X19', 'X20', 'X21', 'X22', 'X23', 'X24', 'X25', 'X26']\n",
      "Instrument variable(s): None\n",
      "No. Observations: 9915\n",
      "\n",
      "------------------ Score & algorithm ------------------\n",
      "Score function: partialling out\n",
      "DML algorithm: dml2\n",
      "\n",
      "------------------ Machine learner   ------------------\n",
      "Learner ml_l: RandomForestRegressor(ccp_alpha=0.001, min_samples_leaf=10)\n",
      "Learner ml_m: RandomForestRegressor(ccp_alpha=0.001, min_samples_leaf=10)\n",
      "Out-of-sample Performance:\n",
      "Learner ml_l RMSE: [[55301.91001332]]\n",
      "Learner ml_m RMSE: [[0.44559897]]\n",
      "\n",
      "------------------ Resampling        ------------------\n",
      "No. folds: 3\n",
      "No. repeated sample splits: 1\n",
      "Apply cross-fitting: True\n",
      "\n",
      "------------------ Fit summary       ------------------\n",
      "          coef     std err         t         P>|t|        2.5 %        97.5 %\n",
      "d  8615.366912  1325.12477  6.501551  7.949582e-11  6018.170088  11212.563736\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "rf = dml.DoubleMLPLR(dml_data, \n",
    "                    RandomForestRegressor(n_estimators=100, min_samples_leaf=10, ccp_alpha=.001), \n",
    "                    RandomForestRegressor(n_estimators=100, min_samples_leaf=10, ccp_alpha=.001), \n",
    "                    n_folds=3)\n",
    "print(rf.fit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56a51b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== DoubleMLPLR Object ==================\n",
      "\n",
      "------------------ Data summary      ------------------\n",
      "Outcome variable: y\n",
      "Treatment variable(s): ['d']\n",
      "Covariates: ['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12', 'X13', 'X14', 'X15', 'X16', 'X17', 'X18', 'X19', 'X20', 'X21', 'X22', 'X23', 'X24', 'X25', 'X26']\n",
      "Instrument variable(s): None\n",
      "No. Observations: 9915\n",
      "\n",
      "------------------ Score & algorithm ------------------\n",
      "Score function: partialling out\n",
      "DML algorithm: dml2\n",
      "\n",
      "------------------ Machine learner   ------------------\n",
      "Learner ml_l: GradientBoostingRegressor(max_depth=5, n_iter_no_change=10)\n",
      "Learner ml_m: GradientBoostingRegressor(max_depth=5, n_iter_no_change=10)\n",
      "Out-of-sample Performance:\n",
      "Learner ml_l RMSE: [[60896.96883926]]\n",
      "Learner ml_m RMSE: [[0.44676685]]\n",
      "\n",
      "------------------ Resampling        ------------------\n",
      "No. folds: 3\n",
      "No. repeated sample splits: 1\n",
      "Apply cross-fitting: True\n",
      "\n",
      "------------------ Fit summary       ------------------\n",
      "          coef      std err         t         P>|t|        2.5 %       97.5 %\n",
      "d  7990.553116  1490.042157  5.362636  8.201636e-08  5070.124153  10910.98208\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosted Tree\n",
    "\n",
    "gbt = dml.DoubleMLPLR(dml_data, \n",
    "                    GradientBoostingRegressor(max_depth=5, n_iter_no_change=10), \n",
    "                    GradientBoostingRegressor(max_depth=5, n_iter_no_change=10), \n",
    "                    n_folds=3)\n",
    "print(gbt.fit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5164819a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== DoubleMLPLR Object ==================\n",
      "\n",
      "------------------ Data summary      ------------------\n",
      "Outcome variable: y\n",
      "Treatment variable(s): ['d']\n",
      "Covariates: ['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12', 'X13', 'X14', 'X15', 'X16', 'X17', 'X18', 'X19', 'X20', 'X21', 'X22', 'X23', 'X24', 'X25', 'X26']\n",
      "Instrument variable(s): None\n",
      "No. Observations: 9915\n",
      "\n",
      "------------------ Score & algorithm ------------------\n",
      "Score function: partialling out\n",
      "DML algorithm: dml2\n",
      "\n",
      "------------------ Machine learner   ------------------\n",
      "Learner ml_l: DecisionTreeRegressor(ccp_alpha=0.001, min_samples_leaf=10)\n",
      "Learner ml_m: DecisionTreeRegressor(ccp_alpha=0.001, min_samples_leaf=10)\n",
      "Out-of-sample Performance:\n",
      "Learner ml_l RMSE: [[60624.47696777]]\n",
      "Learner ml_m RMSE: [[0.44708798]]\n",
      "\n",
      "------------------ Resampling        ------------------\n",
      "No. folds: 3\n",
      "No. repeated sample splits: 1\n",
      "Apply cross-fitting: True\n",
      "\n",
      "------------------ Fit summary       ------------------\n",
      "          coef      std err         t         P>|t|        2.5 %        97.5 %\n",
      "d  8728.355244  1474.746388  5.918547  3.247990e-09  5837.905437  11618.805051\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "dt = dml.DoubleMLPLR(dml_data, \n",
    "                    DecisionTreeRegressor(min_samples_leaf=10, ccp_alpha=.001), \n",
    "                    DecisionTreeRegressor(min_samples_leaf=10, ccp_alpha=.001), \n",
    "                    n_folds=3)\n",
    "print(dt.fit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ccf3bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== DoubleMLIRM Object ==================\n",
      "\n",
      "------------------ Data summary      ------------------\n",
      "Outcome variable: y\n",
      "Treatment variable(s): ['d']\n",
      "Covariates: ['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12', 'X13', 'X14', 'X15', 'X16', 'X17', 'X18', 'X19', 'X20', 'X21', 'X22', 'X23', 'X24', 'X25', 'X26']\n",
      "Instrument variable(s): None\n",
      "No. Observations: 9915\n",
      "\n",
      "------------------ Score & algorithm ------------------\n",
      "Score function: ATE\n",
      "DML algorithm: dml2\n",
      "\n",
      "------------------ Machine learner   ------------------\n",
      "Learner ml_g: RandomForestRegressor(ccp_alpha=0.001, min_samples_leaf=10)\n",
      "Learner ml_m: RandomForestClassifier(ccp_alpha=0.001, min_samples_leaf=10)\n",
      "Out-of-sample Performance:\n",
      "Learner ml_g0 RMSE: [[48043.1981954]]\n",
      "Learner ml_g1 RMSE: [[65238.56900373]]\n",
      "Learner ml_m RMSE: [[0.44509545]]\n",
      "\n",
      "------------------ Resampling        ------------------\n",
      "No. folds: 3\n",
      "No. repeated sample splits: 1\n",
      "Apply cross-fitting: True\n",
      "\n",
      "------------------ Fit summary       ------------------\n",
      "          coef      std err         t         P>|t|        2.5 %       97.5 %\n",
      "d  7565.569811  1151.591879  6.569662  5.042948e-11  5308.491204  9822.648418\n"
     ]
    }
   ],
   "source": [
    "# Doubly Robust Random Forest\n",
    "\n",
    "drrf = dml.DoubleMLIRM(dml_data, \n",
    "                       RandomForestRegressor(n_estimators=100, min_samples_leaf=10, ccp_alpha=.001), \n",
    "                       RandomForestClassifier(n_estimators=100, min_samples_leaf=10, ccp_alpha=.001), \n",
    "                       n_folds=3)\n",
    "\n",
    "print(drrf.fit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1359e8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== DoubleMLIRM Object ==================\n",
      "\n",
      "------------------ Data summary      ------------------\n",
      "Outcome variable: y\n",
      "Treatment variable(s): ['d']\n",
      "Covariates: ['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12', 'X13', 'X14', 'X15', 'X16', 'X17', 'X18', 'X19', 'X20', 'X21', 'X22', 'X23', 'X24', 'X25', 'X26']\n",
      "Instrument variable(s): None\n",
      "No. Observations: 9915\n",
      "\n",
      "------------------ Score & algorithm ------------------\n",
      "Score function: ATE\n",
      "DML algorithm: dml2\n",
      "\n",
      "------------------ Machine learner   ------------------\n",
      "Learner ml_g: GradientBoostingRegressor(max_depth=5, n_iter_no_change=10)\n",
      "Learner ml_m: GradientBoostingClassifier(max_depth=5, n_iter_no_change=10)\n",
      "Out-of-sample Performance:\n",
      "Learner ml_g0 RMSE: [[51636.64732086]]\n",
      "Learner ml_g1 RMSE: [[72580.5371667]]\n",
      "Learner ml_m RMSE: [[0.44785273]]\n",
      "\n",
      "------------------ Resampling        ------------------\n",
      "No. folds: 3\n",
      "No. repeated sample splits: 1\n",
      "Apply cross-fitting: True\n",
      "\n",
      "------------------ Fit summary       ------------------\n",
      "          coef      std err         t         P>|t|        2.5 %       97.5 %\n",
      "d  6593.161932  1256.628144  5.246709  1.548404e-07  4130.216028  9056.107837\n"
     ]
    }
   ],
   "source": [
    "# Doubly Robust Gradient Boosted Tree\n",
    "\n",
    "drgbt = dml.DoubleMLIRM(dml_data, \n",
    "                       GradientBoostingRegressor(max_depth=5, n_iter_no_change=10), \n",
    "                       GradientBoostingClassifier(max_depth=5, n_iter_no_change=10), \n",
    "                       n_folds=3)\n",
    "\n",
    "print(drgbt.fit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac5ae5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== DoubleMLIRM Object ==================\n",
      "\n",
      "------------------ Data summary      ------------------\n",
      "Outcome variable: y\n",
      "Treatment variable(s): ['d']\n",
      "Covariates: ['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12', 'X13', 'X14', 'X15', 'X16', 'X17', 'X18', 'X19', 'X20', 'X21', 'X22', 'X23', 'X24', 'X25', 'X26']\n",
      "Instrument variable(s): None\n",
      "No. Observations: 9915\n",
      "\n",
      "------------------ Score & algorithm ------------------\n",
      "Score function: ATE\n",
      "DML algorithm: dml2\n",
      "\n",
      "------------------ Machine learner   ------------------\n",
      "Learner ml_g: DecisionTreeRegressor(ccp_alpha=0.001, min_samples_leaf=10)\n",
      "Learner ml_m: DecisionTreeClassifier(ccp_alpha=0.001, min_samples_leaf=10)\n",
      "Out-of-sample Performance:\n",
      "Learner ml_g0 RMSE: [[52806.09384908]]\n",
      "Learner ml_g1 RMSE: [[70325.56721675]]\n",
      "Learner ml_m RMSE: [[0.44661613]]\n",
      "\n",
      "------------------ Resampling        ------------------\n",
      "No. folds: 3\n",
      "No. repeated sample splits: 1\n",
      "Apply cross-fitting: True\n",
      "\n",
      "------------------ Fit summary       ------------------\n",
      "          coef      std err         t         P>|t|        2.5 %      97.5 %\n",
      "d  7414.368647  1205.663942  6.149615  7.767142e-10  5051.310744  9777.42655\n"
     ]
    }
   ],
   "source": [
    "# Doubly Robust Decision Tree\n",
    "\n",
    "\n",
    "drdt = dml.DoubleMLIRM(dml_data, \n",
    "                       DecisionTreeRegressor(min_samples_leaf=10, ccp_alpha=.001), \n",
    "                       DecisionTreeClassifier(min_samples_leaf=10, ccp_alpha=.001), \n",
    "                       n_folds=3)\n",
    "\n",
    "print(drdt.fit())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e2520a",
   "metadata": {},
   "source": [
    "I was able to implement all the different model types with both PLM and IRM models, using both EconML and DoubleML. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f81007",
   "metadata": {},
   "source": [
    "### Part d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02bffe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class semisynth:\n",
    "    \n",
    "    def fit(self, X, D, y):\n",
    "        self.X_ = X.copy()\n",
    "        self.est0_ = make_pipeline(transformer,\n",
    "                                   RandomForestRegressor(min_samples_leaf=20, ccp_alpha=0.001)).fit(X[D==0], y[D==0])\n",
    "        self.res0_ = y[D==0] - self.est0_.predict(X[D==0])\n",
    "        self.res0_ -= np.mean(self.res0_)\n",
    "        self.est1_ = make_pipeline(transformer,\n",
    "                                   RandomForestRegressor(min_samples_leaf=20, ccp_alpha=0.001)).fit(X[D==1], y[D==1])\n",
    "        self.res1_ = y[D==1] - self.est1_.predict(X[D==1])\n",
    "        self.res1_ -= np.mean(self.res1_)\n",
    "        self.prop_ = make_pipeline(transformer,\n",
    "                                   RandomForestClassifier(min_samples_leaf=20, ccp_alpha=0.001)).fit(X, D)\n",
    "        return self\n",
    "\n",
    "    def generate_data(self, n):\n",
    "        X = self.X_.iloc[np.random.choice(self.X_.shape[0], n, replace=True)]\n",
    "        D = np.random.binomial(1, self.prop_.predict_proba(X)[:, 1])\n",
    "        y0 = self.est0_.predict(X) + self.res0_[np.random.choice(self.res0_.shape[0], n, replace=True)]\n",
    "        y1 = self.est1_.predict(X) + self.res1_[np.random.choice(self.res1_.shape[0], n, replace=True)]\n",
    "        y = y0 * (1 - D) + y1 * D\n",
    "        return X, D, y, y1, y0\n",
    "    \n",
    "    def y_cef(self, X, D):\n",
    "        return self.est1_.predict(X) * D + self.est0_.predict(X) * (1 - D)\n",
    "    \n",
    "    def D_cef(self, X):\n",
    "        return self.prop_.predict_proba(X)[:, 1]\n",
    "\n",
    "    @property\n",
    "    def true_ate(self):\n",
    "        return np.mean(self.est1_.predict(self.X_) - self.est0_.predict(self.X_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "411fb384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/latex": [
       "$\\displaystyle 7456.88503104321$"
      ],
      "text/plain": [
       "7456.8850310432135"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synth = semisynth()\n",
    "\n",
    "synth.fit(X, D, y)\n",
    "\n",
    "synth.true_ate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "99153ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(point, stderr, yhat, Dhat, resy, resD, epsilon, X, D, y, *, name):\n",
    "    '''\n",
    "    Convenience summary function that takes the results of the DML function\n",
    "    and summarizes several estimation quantities and performance metrics.\n",
    "    '''\n",
    "    return pd.DataFrame({'estimate': point, # point estimate\n",
    "                         'stderr': stderr, # standard error\n",
    "                         'lower': point - 1.96*stderr, # lower end of 95% confidence interval\n",
    "                         'upper': point + 1.96*stderr, # upper end of 95% confidence interval\n",
    "                         'rmse y': np.sqrt(np.mean(resy**2)), # RMSE of model that predicts outcome y\n",
    "                         'rmse D': np.sqrt(np.mean(resD**2)), # RMSE of model that predicts treatment D\n",
    "                         'estimate error': np.abs(point - synth.true_ate), # binary classification accuracy of model for D\n",
    "                         'rmse E[y|D,X]': np.sqrt(np.mean((yhat - synth.y_cef(X, D))**2)), # RMSE wrt true function E[y|X]\n",
    "                         'rmse E[D|X]': np.sqrt(np.mean((Dhat - synth.D_cef(X))**2)), # RMSE wrt true funciton E[D|X]\n",
    "                         'coverage': (point - 1.96*stderr <= synth.true_ate) & (point + 1.96*stderr >= synth.true_ate)\n",
    "                         }, index=[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "73ce4cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimate</th>\n",
       "      <th>stderr</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>rmse y</th>\n",
       "      <th>rmse D</th>\n",
       "      <th>estimate error</th>\n",
       "      <th>rmse E[y|D,X]</th>\n",
       "      <th>rmse E[D|X]</th>\n",
       "      <th>coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>double lasso</th>\n",
       "      <td>8521.806337</td>\n",
       "      <td>4491.532017</td>\n",
       "      <td>-281.596417</td>\n",
       "      <td>17325.209091</td>\n",
       "      <td>60010.633351</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>1064.921306</td>\n",
       "      <td>17349.446485</td>\n",
       "      <td>0.082055</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dml lasso/logistic</th>\n",
       "      <td>7967.404289</td>\n",
       "      <td>4396.741342</td>\n",
       "      <td>-650.208740</td>\n",
       "      <td>16585.017319</td>\n",
       "      <td>60010.633351</td>\n",
       "      <td>0.469868</td>\n",
       "      <td>510.519258</td>\n",
       "      <td>17349.446485</td>\n",
       "      <td>0.092060</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dml random forest</th>\n",
       "      <td>10051.771391</td>\n",
       "      <td>4480.760019</td>\n",
       "      <td>1269.481754</td>\n",
       "      <td>18834.061028</td>\n",
       "      <td>60149.640435</td>\n",
       "      <td>0.466639</td>\n",
       "      <td>2594.886360</td>\n",
       "      <td>19070.538696</td>\n",
       "      <td>0.092050</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dml decision tree</th>\n",
       "      <td>6457.600634</td>\n",
       "      <td>3966.755975</td>\n",
       "      <td>-1317.241076</td>\n",
       "      <td>14232.442344</td>\n",
       "      <td>64720.488964</td>\n",
       "      <td>0.527258</td>\n",
       "      <td>999.284397</td>\n",
       "      <td>28490.227729</td>\n",
       "      <td>0.260645</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dml boosted forest</th>\n",
       "      <td>10284.526556</td>\n",
       "      <td>4379.393141</td>\n",
       "      <td>1700.915999</td>\n",
       "      <td>18868.137112</td>\n",
       "      <td>59813.118428</td>\n",
       "      <td>0.465398</td>\n",
       "      <td>2827.641524</td>\n",
       "      <td>18120.169985</td>\n",
       "      <td>0.083616</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dml AutoML</th>\n",
       "      <td>10126.908159</td>\n",
       "      <td>4551.842048</td>\n",
       "      <td>1205.297745</td>\n",
       "      <td>19048.518572</td>\n",
       "      <td>58989.856502</td>\n",
       "      <td>0.465666</td>\n",
       "      <td>2670.023128</td>\n",
       "      <td>15998.845375</td>\n",
       "      <td>0.099215</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dml stacked (semi-cfit)</th>\n",
       "      <td>8341.029613</td>\n",
       "      <td>4401.579046</td>\n",
       "      <td>-286.065317</td>\n",
       "      <td>16968.124543</td>\n",
       "      <td>59525.184686</td>\n",
       "      <td>0.464504</td>\n",
       "      <td>884.144582</td>\n",
       "      <td>16221.954129</td>\n",
       "      <td>0.077575</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dml best (semi-cfit)</th>\n",
       "      <td>8677.319864</td>\n",
       "      <td>4565.626541</td>\n",
       "      <td>-271.308156</td>\n",
       "      <td>17625.947884</td>\n",
       "      <td>60004.162239</td>\n",
       "      <td>0.464585</td>\n",
       "      <td>1220.434833</td>\n",
       "      <td>18659.878279</td>\n",
       "      <td>0.086959</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dr lasso/logistic</th>\n",
       "      <td>7531.580349</td>\n",
       "      <td>4685.892610</td>\n",
       "      <td>-1652.769167</td>\n",
       "      <td>16715.929866</td>\n",
       "      <td>59472.131695</td>\n",
       "      <td>0.469868</td>\n",
       "      <td>74.695318</td>\n",
       "      <td>16550.461067</td>\n",
       "      <td>0.092060</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dr random forest</th>\n",
       "      <td>9854.949749</td>\n",
       "      <td>5111.070684</td>\n",
       "      <td>-162.748791</td>\n",
       "      <td>19872.648289</td>\n",
       "      <td>60235.138260</td>\n",
       "      <td>0.465427</td>\n",
       "      <td>2398.064718</td>\n",
       "      <td>19800.781052</td>\n",
       "      <td>0.090841</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dr decision tree</th>\n",
       "      <td>3251.736744</td>\n",
       "      <td>25925.879849</td>\n",
       "      <td>-47562.987760</td>\n",
       "      <td>54066.461248</td>\n",
       "      <td>63068.096773</td>\n",
       "      <td>0.522132</td>\n",
       "      <td>4205.148287</td>\n",
       "      <td>27920.772204</td>\n",
       "      <td>0.257644</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dr boosted forest</th>\n",
       "      <td>7639.858022</td>\n",
       "      <td>4290.207471</td>\n",
       "      <td>-768.948621</td>\n",
       "      <td>16048.664665</td>\n",
       "      <td>62130.107023</td>\n",
       "      <td>0.466750</td>\n",
       "      <td>182.972991</td>\n",
       "      <td>24923.269620</td>\n",
       "      <td>0.091855</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dr stacked (semi-cfit)</th>\n",
       "      <td>9101.251585</td>\n",
       "      <td>4491.067823</td>\n",
       "      <td>298.758652</td>\n",
       "      <td>17903.744519</td>\n",
       "      <td>59004.028327</td>\n",
       "      <td>0.464558</td>\n",
       "      <td>1644.366554</td>\n",
       "      <td>15422.298043</td>\n",
       "      <td>0.078817</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dr best (semi-cfit)</th>\n",
       "      <td>9404.043599</td>\n",
       "      <td>4812.306314</td>\n",
       "      <td>-28.076776</td>\n",
       "      <td>18836.163974</td>\n",
       "      <td>59472.131695</td>\n",
       "      <td>0.465410</td>\n",
       "      <td>1947.158568</td>\n",
       "      <td>16550.461067</td>\n",
       "      <td>0.093083</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             estimate        stderr         lower  \\\n",
       "double lasso              8521.806337   4491.532017   -281.596417   \n",
       "dml lasso/logistic        7967.404289   4396.741342   -650.208740   \n",
       "dml random forest        10051.771391   4480.760019   1269.481754   \n",
       "dml decision tree         6457.600634   3966.755975  -1317.241076   \n",
       "dml boosted forest       10284.526556   4379.393141   1700.915999   \n",
       "dml AutoML               10126.908159   4551.842048   1205.297745   \n",
       "dml stacked (semi-cfit)   8341.029613   4401.579046   -286.065317   \n",
       "dml best (semi-cfit)      8677.319864   4565.626541   -271.308156   \n",
       "dr lasso/logistic         7531.580349   4685.892610  -1652.769167   \n",
       "dr random forest          9854.949749   5111.070684   -162.748791   \n",
       "dr decision tree          3251.736744  25925.879849 -47562.987760   \n",
       "dr boosted forest         7639.858022   4290.207471   -768.948621   \n",
       "dr stacked (semi-cfit)    9101.251585   4491.067823    298.758652   \n",
       "dr best (semi-cfit)       9404.043599   4812.306314    -28.076776   \n",
       "\n",
       "                                upper        rmse y    rmse D  estimate error  \\\n",
       "double lasso             17325.209091  60010.633351  0.464844     1064.921306   \n",
       "dml lasso/logistic       16585.017319  60010.633351  0.469868      510.519258   \n",
       "dml random forest        18834.061028  60149.640435  0.466639     2594.886360   \n",
       "dml decision tree        14232.442344  64720.488964  0.527258      999.284397   \n",
       "dml boosted forest       18868.137112  59813.118428  0.465398     2827.641524   \n",
       "dml AutoML               19048.518572  58989.856502  0.465666     2670.023128   \n",
       "dml stacked (semi-cfit)  16968.124543  59525.184686  0.464504      884.144582   \n",
       "dml best (semi-cfit)     17625.947884  60004.162239  0.464585     1220.434833   \n",
       "dr lasso/logistic        16715.929866  59472.131695  0.469868       74.695318   \n",
       "dr random forest         19872.648289  60235.138260  0.465427     2398.064718   \n",
       "dr decision tree         54066.461248  63068.096773  0.522132     4205.148287   \n",
       "dr boosted forest        16048.664665  62130.107023  0.466750      182.972991   \n",
       "dr stacked (semi-cfit)   17903.744519  59004.028327  0.464558     1644.366554   \n",
       "dr best (semi-cfit)      18836.163974  59472.131695  0.465410     1947.158568   \n",
       "\n",
       "                         rmse E[y|D,X]  rmse E[D|X]  coverage  \n",
       "double lasso              17349.446485     0.082055      True  \n",
       "dml lasso/logistic        17349.446485     0.092060      True  \n",
       "dml random forest         19070.538696     0.092050      True  \n",
       "dml decision tree         28490.227729     0.260645      True  \n",
       "dml boosted forest        18120.169985     0.083616      True  \n",
       "dml AutoML                15998.845375     0.099215      True  \n",
       "dml stacked (semi-cfit)   16221.954129     0.077575      True  \n",
       "dml best (semi-cfit)      18659.878279     0.086959      True  \n",
       "dr lasso/logistic         16550.461067     0.092060      True  \n",
       "dr random forest          19800.781052     0.090841      True  \n",
       "dr decision tree          27920.772204     0.257644      True  \n",
       "dr boosted forest         24923.269620     0.091855      True  \n",
       "dr stacked (semi-cfit)    15422.298043     0.078817      True  \n",
       "dr best (semi-cfit)       16550.461067     0.093083      True  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n=1000\n",
    "\n",
    "X, D, y, y1, y0 = synth.generate_data(1000)\n",
    "\n",
    "result = dml(X, D, y, lassoy, lassod, nfolds=3)\n",
    "table = summary(*result, X, D, y, name='double lasso')\n",
    "\n",
    "result = dml(X, D, y, lassoy, lgrd, nfolds=3, classifier=True)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='dml lasso/logistic')])\n",
    "\n",
    "result = dml(X, D, y, rfy, rfd, nfolds=3, classifier=True)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='dml random forest')])\n",
    "\n",
    "result = dml(X, D, y, dtry, dtrd, nfolds=3, classifier=True)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='dml decision tree')])\n",
    "\n",
    "result = dml(X, D, y, gbfy, gbfd, nfolds=3, classifier=True)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='dml boosted forest')])\n",
    "\n",
    "result = dml(X, D, y, flamly, flamld, nfolds=3, classifier=True)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='dml AutoML')])\n",
    "\n",
    "result = dml_dirty(X, D, y, [lassoy, rfy, dtry, gbfy], [lgrd, rfd, dtrd, gbfd],\n",
    "                   nfolds=3, classifier=True)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='dml stacked (semi-cfit)')])\n",
    "\n",
    "result = dml_cf_best(X, D, y, [lassoy, rfy, dtry, gbfy], [lgrd, rfd, dtrd, gbfd],\n",
    "                   nfolds=3, classifier=True)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='dml best (semi-cfit)')])\n",
    "\n",
    "result = dr(X, D, y, lassoy, lassoy, lgrd, nfolds=3)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='dr lasso/logistic')])\n",
    "\n",
    "result = dr(X, D, y, rfy, rfy, rfd, nfolds=3)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='dr random forest')])\n",
    "\n",
    "result = dr(X, D, y, dtry, dtry, dtrd, nfolds=3)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='dr decision tree')])\n",
    "\n",
    "result = dr(X, D, y, gbfy, gbfy, gbfd, nfolds=3)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='dr boosted forest')])\n",
    "\n",
    "result = dr_dirty(X, D, y, [lassoy, rfy, dtry, gbfy], [lassoy, rfy, dtry, gbfy], [lgrd, rfd, dtrd, gbfd], nfolds=3)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='dr stacked (semi-cfit)')])\n",
    "\n",
    "result = dr_cf_best(X, D, y, [lassoy, rfy, dtry, gbfy], [lassoy, rfy, dtry, gbfy], [lgrd, rfd, dtrd, gbfd], nfolds=3)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='dr best (semi-cfit)')])\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fcf5da69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimate</th>\n",
       "      <th>stderr</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>rmse y</th>\n",
       "      <th>rmse D</th>\n",
       "      <th>estimate error</th>\n",
       "      <th>rmse E[y|D,X]</th>\n",
       "      <th>rmse E[D|X]</th>\n",
       "      <th>coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>double lasso</th>\n",
       "      <td>6637.200551</td>\n",
       "      <td>1226.208616</td>\n",
       "      <td>4233.831665</td>\n",
       "      <td>9040.569437</td>\n",
       "      <td>49978.265814</td>\n",
       "      <td>0.454211</td>\n",
       "      <td>819.684480</td>\n",
       "      <td>12916.842988</td>\n",
       "      <td>0.040850</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dml lasso/logistic</th>\n",
       "      <td>6588.965797</td>\n",
       "      <td>1230.213664</td>\n",
       "      <td>4177.747015</td>\n",
       "      <td>9000.184579</td>\n",
       "      <td>49978.265814</td>\n",
       "      <td>0.454332</td>\n",
       "      <td>867.919234</td>\n",
       "      <td>12916.842988</td>\n",
       "      <td>0.041739</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dml random forest</th>\n",
       "      <td>6865.903096</td>\n",
       "      <td>1202.523492</td>\n",
       "      <td>4508.957051</td>\n",
       "      <td>9222.849141</td>\n",
       "      <td>49687.982284</td>\n",
       "      <td>0.454950</td>\n",
       "      <td>590.981935</td>\n",
       "      <td>11887.160973</td>\n",
       "      <td>0.038562</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dml decision tree</th>\n",
       "      <td>7404.736535</td>\n",
       "      <td>1256.197196</td>\n",
       "      <td>4942.590031</td>\n",
       "      <td>9866.883038</td>\n",
       "      <td>52932.440847</td>\n",
       "      <td>0.455662</td>\n",
       "      <td>52.148496</td>\n",
       "      <td>21689.951367</td>\n",
       "      <td>0.046165</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dml boosted forest</th>\n",
       "      <td>6908.600861</td>\n",
       "      <td>1201.663155</td>\n",
       "      <td>4553.341078</td>\n",
       "      <td>9263.860645</td>\n",
       "      <td>49562.387518</td>\n",
       "      <td>0.454698</td>\n",
       "      <td>548.284170</td>\n",
       "      <td>11616.432694</td>\n",
       "      <td>0.037088</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dml AutoML</th>\n",
       "      <td>7414.440810</td>\n",
       "      <td>1192.857414</td>\n",
       "      <td>5076.440279</td>\n",
       "      <td>9752.441341</td>\n",
       "      <td>49566.334685</td>\n",
       "      <td>0.454904</td>\n",
       "      <td>42.444221</td>\n",
       "      <td>11685.244867</td>\n",
       "      <td>0.039175</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dml stacked (semi-cfit)</th>\n",
       "      <td>6830.798747</td>\n",
       "      <td>1208.089602</td>\n",
       "      <td>4462.943128</td>\n",
       "      <td>9198.654366</td>\n",
       "      <td>49336.497727</td>\n",
       "      <td>0.453754</td>\n",
       "      <td>626.086284</td>\n",
       "      <td>10448.087543</td>\n",
       "      <td>0.028796</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dml best (semi-cfit)</th>\n",
       "      <td>6874.774509</td>\n",
       "      <td>1219.453363</td>\n",
       "      <td>4484.645917</td>\n",
       "      <td>9264.903101</td>\n",
       "      <td>49568.197334</td>\n",
       "      <td>0.454332</td>\n",
       "      <td>582.110522</td>\n",
       "      <td>11439.807488</td>\n",
       "      <td>0.041739</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dr lasso/logistic</th>\n",
       "      <td>5965.554611</td>\n",
       "      <td>1235.183728</td>\n",
       "      <td>3544.594503</td>\n",
       "      <td>8386.514719</td>\n",
       "      <td>49870.226450</td>\n",
       "      <td>0.454332</td>\n",
       "      <td>1491.330420</td>\n",
       "      <td>12194.547377</td>\n",
       "      <td>0.041739</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dr random forest</th>\n",
       "      <td>6624.568264</td>\n",
       "      <td>1179.877380</td>\n",
       "      <td>4312.008600</td>\n",
       "      <td>8937.127928</td>\n",
       "      <td>49481.623919</td>\n",
       "      <td>0.454750</td>\n",
       "      <td>832.316767</td>\n",
       "      <td>9891.794112</td>\n",
       "      <td>0.038770</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dr decision tree</th>\n",
       "      <td>5792.690115</td>\n",
       "      <td>1284.801412</td>\n",
       "      <td>3274.479347</td>\n",
       "      <td>8310.900884</td>\n",
       "      <td>52722.573316</td>\n",
       "      <td>0.455662</td>\n",
       "      <td>1664.194916</td>\n",
       "      <td>20638.158963</td>\n",
       "      <td>0.046165</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dr boosted forest</th>\n",
       "      <td>6824.057434</td>\n",
       "      <td>1182.859845</td>\n",
       "      <td>4505.652138</td>\n",
       "      <td>9142.462730</td>\n",
       "      <td>49556.565869</td>\n",
       "      <td>0.455016</td>\n",
       "      <td>632.827597</td>\n",
       "      <td>10796.578005</td>\n",
       "      <td>0.038358</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dr stacked (semi-cfit)</th>\n",
       "      <td>6312.100346</td>\n",
       "      <td>1200.370646</td>\n",
       "      <td>3959.373879</td>\n",
       "      <td>8664.826813</td>\n",
       "      <td>49166.083703</td>\n",
       "      <td>0.453710</td>\n",
       "      <td>1144.784685</td>\n",
       "      <td>8803.552711</td>\n",
       "      <td>0.028669</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dr best (semi-cfit)</th>\n",
       "      <td>6271.895647</td>\n",
       "      <td>1220.562267</td>\n",
       "      <td>3879.593603</td>\n",
       "      <td>8664.197691</td>\n",
       "      <td>49338.137352</td>\n",
       "      <td>0.454332</td>\n",
       "      <td>1184.989384</td>\n",
       "      <td>9986.097390</td>\n",
       "      <td>0.041739</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            estimate       stderr        lower        upper  \\\n",
       "double lasso             6637.200551  1226.208616  4233.831665  9040.569437   \n",
       "dml lasso/logistic       6588.965797  1230.213664  4177.747015  9000.184579   \n",
       "dml random forest        6865.903096  1202.523492  4508.957051  9222.849141   \n",
       "dml decision tree        7404.736535  1256.197196  4942.590031  9866.883038   \n",
       "dml boosted forest       6908.600861  1201.663155  4553.341078  9263.860645   \n",
       "dml AutoML               7414.440810  1192.857414  5076.440279  9752.441341   \n",
       "dml stacked (semi-cfit)  6830.798747  1208.089602  4462.943128  9198.654366   \n",
       "dml best (semi-cfit)     6874.774509  1219.453363  4484.645917  9264.903101   \n",
       "dr lasso/logistic        5965.554611  1235.183728  3544.594503  8386.514719   \n",
       "dr random forest         6624.568264  1179.877380  4312.008600  8937.127928   \n",
       "dr decision tree         5792.690115  1284.801412  3274.479347  8310.900884   \n",
       "dr boosted forest        6824.057434  1182.859845  4505.652138  9142.462730   \n",
       "dr stacked (semi-cfit)   6312.100346  1200.370646  3959.373879  8664.826813   \n",
       "dr best (semi-cfit)      6271.895647  1220.562267  3879.593603  8664.197691   \n",
       "\n",
       "                               rmse y    rmse D  estimate error  \\\n",
       "double lasso             49978.265814  0.454211      819.684480   \n",
       "dml lasso/logistic       49978.265814  0.454332      867.919234   \n",
       "dml random forest        49687.982284  0.454950      590.981935   \n",
       "dml decision tree        52932.440847  0.455662       52.148496   \n",
       "dml boosted forest       49562.387518  0.454698      548.284170   \n",
       "dml AutoML               49566.334685  0.454904       42.444221   \n",
       "dml stacked (semi-cfit)  49336.497727  0.453754      626.086284   \n",
       "dml best (semi-cfit)     49568.197334  0.454332      582.110522   \n",
       "dr lasso/logistic        49870.226450  0.454332     1491.330420   \n",
       "dr random forest         49481.623919  0.454750      832.316767   \n",
       "dr decision tree         52722.573316  0.455662     1664.194916   \n",
       "dr boosted forest        49556.565869  0.455016      632.827597   \n",
       "dr stacked (semi-cfit)   49166.083703  0.453710     1144.784685   \n",
       "dr best (semi-cfit)      49338.137352  0.454332     1184.989384   \n",
       "\n",
       "                         rmse E[y|D,X]  rmse E[D|X]  coverage  \n",
       "double lasso              12916.842988     0.040850      True  \n",
       "dml lasso/logistic        12916.842988     0.041739      True  \n",
       "dml random forest         11887.160973     0.038562      True  \n",
       "dml decision tree         21689.951367     0.046165      True  \n",
       "dml boosted forest        11616.432694     0.037088      True  \n",
       "dml AutoML                11685.244867     0.039175      True  \n",
       "dml stacked (semi-cfit)   10448.087543     0.028796      True  \n",
       "dml best (semi-cfit)      11439.807488     0.041739      True  \n",
       "dr lasso/logistic         12194.547377     0.041739      True  \n",
       "dr random forest           9891.794112     0.038770      True  \n",
       "dr decision tree          20638.158963     0.046165      True  \n",
       "dr boosted forest         10796.578005     0.038358      True  \n",
       "dr stacked (semi-cfit)     8803.552711     0.028669      True  \n",
       "dr best (semi-cfit)        9986.097390     0.041739      True  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n=10000\n",
    "\n",
    "X, D, y, y1, y0 = synth.generate_data(10000)\n",
    "\n",
    "result = dml(X, D, y, lassoy, lassod, nfolds=3)\n",
    "table = summary(*result, X, D, y, name='double lasso')\n",
    "\n",
    "result = dml(X, D, y, lassoy, lgrd, nfolds=3, classifier=True)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='dml lasso/logistic')])\n",
    "\n",
    "result = dml(X, D, y, rfy, rfd, nfolds=3, classifier=True)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='dml random forest')])\n",
    "\n",
    "result = dml(X, D, y, dtry, dtrd, nfolds=3, classifier=True)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='dml decision tree')])\n",
    "\n",
    "result = dml(X, D, y, gbfy, gbfd, nfolds=3, classifier=True)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='dml boosted forest')])\n",
    "\n",
    "result = dml(X, D, y, flamly, flamld, nfolds=3, classifier=True)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='dml AutoML')])\n",
    "\n",
    "result = dml_dirty(X, D, y, [lassoy, rfy, dtry, gbfy], [lgrd, rfd, dtrd, gbfd],\n",
    "                   nfolds=3, classifier=True)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='dml stacked (semi-cfit)')])\n",
    "\n",
    "result = dml_cf_best(X, D, y, [lassoy, rfy, dtry, gbfy], [lgrd, rfd, dtrd, gbfd],\n",
    "                   nfolds=3, classifier=True)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='dml best (semi-cfit)')])\n",
    "\n",
    "result = dr(X, D, y, lassoy, lassoy, lgrd, nfolds=3)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='dr lasso/logistic')])\n",
    "\n",
    "result = dr(X, D, y, rfy, rfy, rfd, nfolds=3)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='dr random forest')])\n",
    "\n",
    "result = dr(X, D, y, dtry, dtry, dtrd, nfolds=3)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='dr decision tree')])\n",
    "\n",
    "result = dr(X, D, y, gbfy, gbfy, gbfd, nfolds=3)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='dr boosted forest')])\n",
    "\n",
    "result = dr_dirty(X, D, y, [lassoy, rfy, dtry, gbfy], [lassoy, rfy, dtry, gbfy], [lgrd, rfd, dtrd, gbfd], nfolds=3)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='dr stacked (semi-cfit)')])\n",
    "\n",
    "result = dr_cf_best(X, D, y, [lassoy, rfy, dtry, gbfy], [lassoy, rfy, dtry, gbfy], [lgrd, rfd, dtrd, gbfd], nfolds=3)\n",
    "table = pd.concat([table, summary(*result,  X, D, y, name='dr best (semi-cfit)')])\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5432510",
   "metadata": {},
   "source": [
    "The autoML and stacked models work well compared to the others. Their estimates are similar and standard errors are close to if not lower than others. This is true for both n=1000 and n=10000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e92ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
